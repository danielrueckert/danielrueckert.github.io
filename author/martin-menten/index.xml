<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Martin Menten | AI in Medicine</title>
    <link>https://aim-lab.io/author/martin-menten/</link>
      <atom:link href="https://aim-lab.io/author/martin-menten/index.xml" rel="self" type="application/rss+xml" />
    <description>Martin Menten</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Technical University of Munich 2023</copyright><lastBuildDate>Wed, 15 Feb 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://aim-lab.io/images/icon_hu90763c276d9f69c3ad22e431a6bb6670_11797_512x512_fill_lanczos_center_2.png</url>
      <title>Martin Menten</title>
      <link>https://aim-lab.io/author/martin-menten/</link>
    </image>
    
    <item>
      <title>MSc Thesis: transfer learning for segmentation of tubular structures in thoracic CT images</title>
      <link>https://aim-lab.io/theses/thoracic_ct_processing/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/thoracic_ct_processing/</guid>
      <description>&lt;p&gt;Computed tomography (CT) scans are commonly used in clinic practice to diagnose and monitor diseases of the lung, heart and upper abdomen [1]. Deep learning has seen wide-spread application for the segmentation of organs in CT images [2,3]. However, its use for segmentation of complex, tubular structures, such as the bronchial proximal airways or cardiac vasculature, has been inhibited by a lack of high-quality ground truth labels [4]. In this research project, the prospective student will investigate the use of unsupervised learning and transfer learning to segment complex structures in chest CT images without having to rely on large amounts of ground truth annotations.&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Enthusiasm for deep learning and biomedical imaging.&lt;/li&gt;
&lt;li&gt;Advanced knowledge of machine learning and computer vision. Ideally, prior work experience using deep learning for image processing.&lt;/li&gt;
&lt;li&gt;Excellent programming skills in Python as well as PyTorch or Tensorflow.&lt;/li&gt;
&lt;li&gt;Full time commitment towards the completion of your Master&amp;rsquo;s project.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Send an email to &lt;a href=&#34;mailto:martin.menten@tum.de&#34;&gt;martin.menten@tum.de&lt;/a&gt; and &lt;a href=&#34;mailto:veronika.zimmer@tum.de&#34;&gt;veronika.zimmer@tum.de&lt;/a&gt; with your CV and transcript. We aim to get back to you within a couple of days.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Grainger, Ronald G., and David J. Allison, eds. Grainger &amp;amp; Allison&amp;rsquo;s diagnostic radiology: a textbook of medical imaging. Vol. 1. Churchill Livingstone, 1997.&lt;br&gt;
[2] Dong, Xue, et al. &amp;ldquo;Automatic multiorgan segmentation in thorax CT images using U‐net‐GAN.&amp;rdquo; Medical physics 46.5 (2019): 2157-2168.&lt;br&gt;
[3] Wasserthal, Jakob, et al. &amp;ldquo;TotalSegmentator: robust segmentation of 104 anatomical structures in CT images.&amp;rdquo; arXiv preprint arXiv:2208.05868 (2022).&lt;br&gt;
[4] Willemink, Martin J., et al. &amp;ldquo;Preparing medical imaging data for machine learning.&amp;rdquo; Radiology 295.1 (2020): 4-15.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Unsupervised deep learning for vessel segmentation in optical coherence tomography angiographs</title>
      <link>https://aim-lab.io/theses/old/octa/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/old/octa/</guid>
      <description>&lt;p&gt;Optical coherence tomography angiography (OCTA) is an imaging technique that visualizes blood vessels by detecting motion of red blood cells in sequential scans [1]. It has seen initial adoption for the diagnosis and monitoring of clinical conditions that affect the retinal vasculature, such as several different eye diseases or multiple sclerosis [2, 3]. However, its effective clinical use is often impeded by the occurrence of imaging artifacts and lack of tools that can extract the vessel maps from the images. Only few studies have explored the use of deep-learning-based segmentation to delineate vessels in two-dimensional OCTA images [4, 5]. The development of three-dimensional (3D) segmentation algorithms has proven difficult due to a lack of publicly available datasets with ground truth annotations, which are difficult and time-consuming to acquire for the large and complex OCTA images [5].&lt;/p&gt;
&lt;p&gt;This project aims at tackling the problem of 3D vessel segmentation in OCTA images using unsupervised and weakly supervised deep learning. The prospective student will adopt existing deep-learning-based segmentation algorithms so that these can be trained using self-supervision and noisy annotations. All developed methods will be evaluated on a large dataset of OCTA images collected at the Klinikum rechts der Isar.&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Enthusiasm for deep learning and biomedical imaging.&lt;/li&gt;
&lt;li&gt;Advanced knowledge of machine learning and computer vision. Ideally, prior work experience using deep learning for image processing.&lt;/li&gt;
&lt;li&gt;Excellent programming skills in Python, PyTorch or Tensorflow. Familiarity with C++ is helpful.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] De Carlo, T. E., Romano, A., Waheed, N. K., &amp;amp; Duker, J. S. (2015). A review of optical coherence tomography angiography (OCTA). International journal of retina and vitreous, 1(1), 5. &lt;/br&gt;
[2] Chalam, K. V., &amp;amp; Sambhav, K. (2016). Optical coherence tomography angiography in retinal diseases. Journal of ophthalmic &amp;amp; vision research, 11(1), 84. &lt;/br&gt;
[3] Feucht, N., Maier, M., Lepennetier, G., Pettenkofer, M., Wetzlmair, C., Daltrozzo, T., &amp;hellip; &amp;amp; Knier, B. (2019). Optical coherence tomography angiography indicates associations of the retinal vascular network and disease activity in multiple sclerosis. Multiple Sclerosis Journal, 25(2), 224-234. &lt;/br&gt;
[4] Mou, L., Zhao, Y., Chen, L., Cheng, J., Gu, Z., Hao, H., &amp;hellip; &amp;amp; Liu, J. (2019, October). CS-Net: channel and spatial attention network for curvilinear structure segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 721-730). Springer, Cham. &lt;/br&gt;
[5] Ma, Y., Hao, H., Xie, J., Fu, H., Zhang, J., Yang, J., &amp;hellip; &amp;amp; Zhao, Y. (2020). ROSE: a retinal OCT-angiography vessel segmentation dataset and new model. IEEE transactions on medical imaging, 40(3), 928-939. &lt;/br&gt;
[6] Schneider, M., Reichold, J., Weber, B., Székely, G., &amp;amp; Hirsch, S. (2012). Tissue metabolism driven arterial tree generation. Medical image analysis, 16(7), 1397-1414. &lt;/br&gt;
[7] Kato, H., Beker, D., Morariu, M., Ando, T., Matsuoka, T., Kehl, W., &amp;amp; Gaidon, A. (2020). Differentiable rendering: A survey. arXiv preprint arXiv:2006.12057.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
