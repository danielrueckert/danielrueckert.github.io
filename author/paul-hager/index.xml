<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paul Hager | AI in Medicine</title>
    <link>https://aim-lab.io/author/paul-hager/</link>
      <atom:link href="https://aim-lab.io/author/paul-hager/index.xml" rel="self" type="application/rss+xml" />
    <description>Paul Hager</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© Technical University of Munich 2023</copyright><lastBuildDate>Thu, 27 Jul 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://aim-lab.io/images/icon_hu90763c276d9f69c3ad22e431a6bb6670_11797_512x512_fill_lanczos_center_3.png</url>
      <title>Paul Hager</title>
      <link>https://aim-lab.io/author/paul-hager/</link>
    </image>
    
    <item>
      <title>MSc Thesis: Multi-Organ Self-Supervised Learning for Efficient Exploitation of Large-Scale (1 million&#43;) Real World Clinical Radiograph Dataset</title>
      <link>https://aim-lab.io/theses/paulhager/multi_organ_self_supervised/</link>
      <pubDate>Thu, 27 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/paulhager/multi_organ_self_supervised/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;As the availability of large clinical datasets continues to grow, the cost and effort associated with manual labeling of medical images become a significant bottleneck in leveraging the full potential of these data. In this research thesis, we aim to investigate the importance of self-supervised learning techniques in harnessing large clinical datasets, where labels are expensive and scarce. Specifically, we explore two prominent self-supervised deep learning approaches: contrastive learning and masked autoencoders.&lt;/p&gt;
&lt;p&gt;Contrastive learning [1] has gained considerable attention due to its ability to learn useful representations without requiring labeled data. However, in the context of large clinical datasets comprising radiography images of multiple anatomical regions, several challenges arise. The need for downsampling to achieve viable batch sizes, coupled with the focus on global features, might limit the effectiveness of contrastive learning, particularly for capturing fine-grained features and retaining the high-resolution information of the images.&lt;/p&gt;
&lt;p&gt;To overcome these limitations, we propose the utilization of masked autoencoders [2], an alternative self-supervised learning technique, for generating strong embeddings from our extensive in-house clinical dataset consisting of over 1 million radiography images across multiple anatomical regions. Masked autoencoders excel at capturing intricate details and preserving fine-grained features due to their ability to reconstruct input data by reconstructing masked portions. This characteristic makes them well-suited for large image sizes and enables them to emphasize local, region-specific information.&lt;/p&gt;
&lt;p&gt;We will evaluate the strength of our embeddings through multiple downstream tasks such as foreign object identification, bone fracture classification, and fracture detection (bounding boxes). We will use a combination of NLP and expert annotations to develop a large enough training dataset for efficient finetuning using minimal labeled data.&lt;/p&gt;
&lt;h2 id=&#34;to-accomplish-this-work-successfully-we-expect-you-to-have&#34;&gt;To accomplish this work successfully, we expect you to have:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Strong coding skills and familiarity with Pytorch&lt;/li&gt;
&lt;li&gt;Basic knowledge of self-supervised methods such as contrastive learning or MAEs&lt;/li&gt;
&lt;li&gt;A strong spirit of independent work and desire to solve interesting, realworld research questions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Access to a massive inhouse dataset of over 1 million medical images&lt;/li&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine.&lt;/li&gt;
&lt;li&gt;Support in bringing your finished project to publication&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://arxiv.org/pdf/2002.05709.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Simple Framework for Contrastive Learning of Visual Representations&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://arxiv.org/abs/2111.06377&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Masked Autoencoders Are Scalable Vision Learners&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Send an email to &lt;a href=&#34;mailto:paul.hager@tum.de&#34;&gt;paul.hager@tum.de&lt;/a&gt; with your CV and transcript. We promise to get back to you within a couple of days.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Spatiotemporal Contrastive Learning of Progressive Diseases</title>
      <link>https://aim-lab.io/theses/paulhager/temporal_contrastive_learning/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/paulhager/temporal_contrastive_learning/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Contrastive learning is currently the most effective way to learn representations in a self-supervised manner. Its strength lies in training networks to solve a context-matching task using multiple views of an image. If the views are smartly chosen through proper augmentations, the model learns informative representations of data without any human supervision. These representations can then be used on targeted downstream tasks.&lt;/p&gt;
&lt;p&gt;Contrastive learning has been explored extensively in the natural image domain but there still remain many unanswered questions and untapped potential in the medical domain. The unique characteristics of medical data offers many avenues to explore to try and determine how best to adapt contrastive learning to medical imaging. In this project, we are interested in the temporal dimension in two very large medical datasets.&lt;/p&gt;
&lt;p&gt;Our main application will be for learning representations of the evolution of progressive diseases. Despite being the leading cause of blindness in the elderly, little is understood about how Age-related macular degeneration (AMD) develops over time. This evolution is documented in our dataset of 181k retinal images of 7.5k subjects imaged over eight years. Using the self-supervised  methodology you develop, you will also learn representations that encode multiple years of disease progression, ultimately improving diagnosis and prognosis of AMD.&lt;/p&gt;
&lt;p&gt;A secondary application, to test the generalisability of the method, is cardiac MR imaging. Here we will train models to learn the dynamics of the heart as it cycles at least one heart beat, which is important for predicting cardiac disease such as infarction. The full cycle cardiac MR data from the UKBB contains over 45k subjects.&lt;/p&gt;
&lt;h2 id=&#34;to-accomplish-this-work-successfully-we-expect-you-to-have&#34;&gt;To accomplish this work successfully, we expect you to have:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Strong coding skills and familiarity with Pytorch&lt;/li&gt;
&lt;li&gt;Basic knowledge of contrastive learning&lt;/li&gt;
&lt;li&gt;A strong spirit of independent work and desire to solve interesting research questions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine.&lt;/li&gt;
&lt;li&gt;Support in bringing your finished project to publication&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://arxiv.org/pdf/2002.05709.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Simple Framework for Contrastive Learning of Visual Representations&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://arxiv.org/pdf/2104.14558.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href=&#34;https://faculty.ucmerced.edu/mhyang/papers/cvpr2021_cvrl.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spatiotemporal Contrastive Video Representation Learning&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Send an email to &lt;a href=&#34;mailto:robert.holland15@imperial.ac.uk&#34;&gt;robert.holland15@imperial.ac.uk&lt;/a&gt; and &lt;a href=&#34;mailto:paul.hager@tum.de&#34;&gt;paul.hager@tum.de&lt;/a&gt; with your CV and transcript. We promise to get back to you within a couple of days.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
