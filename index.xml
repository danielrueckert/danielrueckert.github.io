<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI in Medicine</title>
    <link>https://aim-lab.io/</link>
      <atom:link href="https://aim-lab.io/index.xml" rel="self" type="application/rss+xml" />
    <description>AI in Medicine</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Technical University of Munich 2021</copyright><lastBuildDate>Mon, 03 May 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://aim-lab.io/images/icon_hu90763c276d9f69c3ad22e431a6bb6670_11797_512x512_fill_lanczos_center_2.png</url>
      <title>AI in Medicine</title>
      <link>https://aim-lab.io/</link>
    </image>
    
    <item>
      <title>MSc Thesis: Transformer-based Optical Flow Estimation in General Computer Vision</title>
      <link>https://aim-lab.io/theses/transformer/</link>
      <pubDate>Mon, 03 May 2021 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/transformer/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Deep learning has reached a new era in 2021, with Transformer-based networks making a name for themselves in Computer vision tasks, topping the Leaderboard in Recognition, Detection and Segmentation [1-3]. However, the power of Transformers has not been researched in optical flow estimation. Based on our current knowledge about optical flow and Transformers, we believe that Transformer has the potential to surpass the state-of-the-art convolution-based networks like [4-6] in the field of flow estimation. During this project, you will develop a brand new transformer-based neural network aiming at solving the flow estimation problem, and test them on leading benchmarks like Sintel [7] and KITTI [8]. Are you ready for this challenge?&lt;/p&gt;
&lt;h2 id=&#34;we-offer&#34;&gt;We offer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A warm start of the project with the state-of-the-art knowledge of the group in this field&lt;/li&gt;
&lt;li&gt;A chance to collaborate with international experts in Deep learning who have connected with our lab&lt;/li&gt;
&lt;li&gt;A chance to publish if the work shines&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;we-expect-you-have&#34;&gt;We expect you have&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Strong background in linear algebra and Deep Learning, familiar with the classic CNN backbones&lt;/li&gt;
&lt;li&gt;proficiency in Python, experience with Tensorflow, Pytorch and/or JAX&lt;/li&gt;
&lt;li&gt;Knowledge in Optical Flow Estimation and/or Transformer would be a big plus&lt;/li&gt;
&lt;li&gt;Passions in Research and Computer vision (which is the most important thing)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are interested in this work and ready for a new challenge, please feel free to contact us:)&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In International Confer- ence on Learning Representations, 2021.&lt;/p&gt;
&lt;p&gt;[2] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai. Deformable DETR: Deformable transformers for end-to-end object detection. In International Conference on Learning Representations, 2021.&lt;/p&gt;
&lt;p&gt;[3] Ze Liu, Yutong Lin, Yue Ca, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo. Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. 2021. arxiv.org/abs/2103.14030&lt;/p&gt;
&lt;p&gt;[4] Dosovitskiy A., Fischer P., Ilg E., Häusser P., Hazırbas C., Golkov V., Smagt P., Cremers D., Brox T.: FlowNet: Learning optical flow with convolutional networks. In: Proceedings of the Fifteenth IEEE International Conference on Computer Vision, pp. 2758–2766. Santiago, Chile, 2015&lt;/p&gt;
&lt;p&gt;[5] Sun D., Yang X., Liu M.Y., Kautz J.: PWC-Net: CNNs for optical flow using pyramid, warping, and cost volume. In: Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 8934–8943. Salt Lake City, Utah, 2018&lt;/p&gt;
&lt;p&gt;[6] Teed Z., Deng J., RAFT: Recurrent All-Pairs Field Transforms for Optical Flow. In European Conference on Computer Vision, pp. 402-419, 2020&lt;/p&gt;
&lt;p&gt;[7] Butler D.J., Wulff J., Stanley G.B., Black M.J.: A naturalistic open source movie for optical flow evaluation. In: European conference on computer vision. pp. 611–625. Springer, 2012&lt;/p&gt;
&lt;p&gt;[8] Geiger A., Lenz P., Stiller C., Urtasun R.: Vision meets robotics: The kitti dataset. The International Journal of Robotics Research 32(11), 1231–1237, 2013&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Deep Natural Language Processing for Radiology Reports</title>
      <link>https://aim-lab.io/theses/nlp/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/nlp/</guid>
      <description>&lt;p&gt;In recent years deep learning has proven quite successful in the field of natural language processing (NLP). However, many of today’s NLP models require very large datasets for training, thus self-supervised pre-training (like BERT [1]) on large unlabeled datasets has become quite important.&lt;/p&gt;
&lt;p&gt;We want to apply deep NLP models (like transformers) to radiology reports and do predictions on them. While there is a large variety of pre-trained models available which we could utilize for this task (like [2,3]), these models suffer from a language domain-shift when directly applied to German radiology reports as available models are typically not pre-trained on German medical language.
Thus, our goal is to pre-train a NLP model for the domain of German radiology reports such that the resulting model can be easily fine-tuned for prediction tasks.&lt;/p&gt;
&lt;p&gt;We offer flexibility regarding the objectives of this MSc thesis.
Possible tasks may include but are not limited to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Domain adaptation of pre-trained models&lt;/li&gt;
&lt;li&gt;Adaption or development of a pre-training strategy for radiology reports&lt;/li&gt;
&lt;li&gt;Development of a model architecture for radiology reports&lt;/li&gt;
&lt;li&gt;Development of a data augmentation strategy&lt;/li&gt;
&lt;li&gt;Utilization of additional data sources for pre-training (e.g. Wikipedia or books)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can define the topic of your thesis, such that it matches your interests as good as possible.&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Strong background in deep learning&lt;/li&gt;
&lt;li&gt;Proficient in Python&lt;/li&gt;
&lt;li&gt;Experience with ML frameworks, preferable PyTorch&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Prior experience or knowledge (e.g. lectures) in NLP is beneficial but not required.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;J. Devlin et al. &amp;ldquo;Bert: Pre-training of deep bidirectional transformers for language understanding.&amp;rdquo; arXiv preprint &lt;a href=&#34;https://arxiv.org/abs/1810.04805&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1810.04805&lt;/a&gt; (2018).&lt;/li&gt;
&lt;li&gt;E. Alsentzer et al. “Publicly Available Clinical BERT Embeddings.” arXiv preprint &lt;a href=&#34;https://arxiv.org/abs/1904.03323&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1904.03323&lt;/a&gt; (2019)&lt;/li&gt;
&lt;li&gt;B. Chan et al. “German’s Next Language Model.” arXiv preprint &lt;a href=&#34;https://arxiv.org/abs/2010.10906&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:2010.10906&lt;/a&gt; (2020)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Seminar on Federated Learning (SoSe2021)</title>
      <link>https://aim-lab.io/theses/federated/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/federated/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://campus.tum.de/tumonline/WBMODHB.wbShowMHBReadOnly?pKnotenNr=1248712&amp;amp;pOrgNr=14189&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Master Seminar (IN2107, IN4410)&lt;/a&gt; (2 SWS, 5 ECTS) offered for BioMedical Computing (BMC) program at the Chair for Computer Aided Medical Procedures and Augmented Reality, TU Munich&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Organizers:&lt;/strong&gt; Dr. Shadi Albarqouni, Helmholtz AI and TU Munich, Prof. Nassir Navab, Chair for Computer Aided Medical Procedures, and Prof. Daniel Rueckert, Chair for AI in Medicine, TU Munich&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tutors&lt;/strong&gt;: Cosmin Bercea&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: Fridays, 10:00 - 12:00&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Following the great success of our on-going seminar on Deep Learning for Medical Applications, we would like to discuss advanced topics that are quite relevant to Federated Learning which becomes an interesting and hot research direction in the community. In simple words, Federated Learning enables training models at the client-side while preserving their privacy, and aggregates the knowledge from the nodes to learn a global model. The interesting part here that the data are kept private and not transmitted to any other nodes. Instead, the characteristics (e.g. parameters) of the global model are shared with the clients, and once the training is done locally, the characteristics are sent back to the global one for aggregation. This learning paradigm has been received quite nicely in the community, in particular, for sensitive domains, e.g. Healthcare. To push this momentum, we proposed, together with our academia and industry partners, a workshop on Federated, Collaborative, and Distributed Learning in the International Conference on Medical Image Computing and Computer-Aided Intervention (MICCAI) to attract significant contributions attacking the challenges in Medical Imaging and Healthcare. In this seminar, we will be discussing the relevant papers on Federated Learning with an emphasis on the papers tackling the common challenges in Medical Imaging, e.g. data heterogeneity, domain shift, and non-iid distributed data.&lt;/p&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;For full details on the course please follow &lt;a href=&#34;https://albarqouni.github.io/courses/flhsose2021/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The developing Human Connectome Project (dHCP) automated resting-state functional processing framework for newborn infants</title>
      <link>https://aim-lab.io/publication/neuroimage2020a/</link>
      <pubDate>Sat, 21 Nov 2020 21:26:19 +0100</pubDate>
      <guid>https://aim-lab.io/publication/neuroimage2020a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MSc Thesis: Machine Learning in Fetal MRI Reconstruction</title>
      <link>https://aim-lab.io/theses/fetal/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/fetal/</guid>
      <description>&lt;p&gt;Fetal Magnetic Resonance Imaging (MRI) has become increasingly important to assess the development of the fetal brain. However, the acquisition is challenging due to the uncontrollable fetal motion. This requires both improved MR acquisition and reconstruction procedures. The objective of this thesis is to develop a learning-based reconstruction pipeline to reconstruct and monitor the fetal heartbeat and to investigate how we can transfer knowledge from adult cardiac MRI reconstruction to fetal cardiac MRI.&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Computer Science, Biomedical Engineering or similar background&lt;/li&gt;
&lt;li&gt;Strong background in machine learning&lt;/li&gt;
&lt;li&gt;Interest in medical imaging&lt;/li&gt;
&lt;li&gt;Proficient  in Python&lt;/li&gt;
&lt;li&gt;Experience with ML frameworks, e.g., PyTorch / Tensorflow / Keras (optional)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;we-offer&#34;&gt;We offer&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;a close, personal supervision&lt;/li&gt;
&lt;li&gt;to work in an interdisciplinary team&lt;/li&gt;
&lt;li&gt;to collaborate with international experts in machine learning and MR image reconstruction.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Motion-Compensated MRI Reconstruction</title>
      <link>https://aim-lab.io/theses/motionmri/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/motionmri/</guid>
      <description>&lt;p&gt;Long acquisition times in Magnetic Resonance Imaging (MRI) bear the risk of patient motion, which substantially degrades the image quality. Further sources of image degradation are physiological motion, such as periodic respiratory and cardiac motion. Accelerated acquisitions can compensate for the motion. The motion information can also be derived from the acquired MRI data retrospectively and used as a correction step in image reconstruction. The objective of this thesis is to include the motion model directly in MRI reconstruction using both knowledge of the acquisition physics and machine learning. Motion-Compensated MRI reconstruction offers a wide range of opportunities for projects, where we can set the emphasis based on your interests. Please get in touch with us to find an individual topic!&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Computer Science, Biomedical Engineering or similar background&lt;/li&gt;
&lt;li&gt;Strong background in machine learning&lt;/li&gt;
&lt;li&gt;Interest in medical imaging&lt;/li&gt;
&lt;li&gt;Proficient  in Python&lt;/li&gt;
&lt;li&gt;Experience with ML frameworks, e.g., PyTorch / Tensorflow / Keras (optional)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;we-offer&#34;&gt;We offer&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;a close, personal supervision&lt;/li&gt;
&lt;li&gt;to work in an interdisciplinary team&lt;/li&gt;
&lt;li&gt;to collaborate with international experts in machine learning and MR image reconstruction.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Physics-Driven Self-Supervised Learning in MRI Reconstruction</title>
      <link>https://aim-lab.io/theses/physicsmri/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/physicsmri/</guid>
      <description>&lt;p&gt;Machine learning has evolved tremendously to accelerate the inherently low acquisition process of Magnetic Resonance (MR) images. However, it is challenging to obtain ground truth data for learning MRI reconstruction. The objective of this MSc thesis is to explore self-supervised learning for MRI reconstruction, where only the measurement (k-space) data and knowledge about the acquisition physics are available. The tasks are to get an overview of the field (literature review), to test existing methods, and to develop novel methods on MRI data.&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Computer Science, Biomedical Engineering or similar background&lt;/li&gt;
&lt;li&gt;Strong background in machine learning&lt;/li&gt;
&lt;li&gt;Interest in medical imaging&lt;/li&gt;
&lt;li&gt;Proficient  in Python&lt;/li&gt;
&lt;li&gt;Experience with ML frameworks, e.g., PyTorch / Tensorflow / Keras (optional)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;we-offer&#34;&gt;We offer&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;a close, personal supervision&lt;/li&gt;
&lt;li&gt;to work in an interdisciplinary team&lt;/li&gt;
&lt;li&gt;to collaborate with international experts in machine learning and MR image reconstruction.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Distributionally robust neural networks in medical imaging</title>
      <link>https://aim-lab.io/theses/robust/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/robust/</guid>
      <description>&lt;p&gt;Deep learning has revolutionized the field of medical imaging. However, the performance of a model drops when the distribution of the test data is different from the distribution of the training data. This is especially critical in a medical setting, where the amount of labelled training data is often limited, and in particular for the application in clinical routine, where the distribution of the test data cannot be controlled. Typical problems are here domain shift, bias in the training data and out-of-distribution samples (e.g., pathologies, image artefacts).
In this project, we will explore distributionally robust optimization (DRO) [1,2] for deep learning in medical imaging. Instead of minimizing the average loss of a training set, DRO minimizes the worst-case risk and with this optimizes the performances on ”hard” examples. The student will adapt and develop novel methods using DRO for medical imaging applications (classification, segmentation and/or registration.&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Prior experience and good understanding in machine learning and statistics.&lt;/li&gt;
&lt;li&gt;Very good programming skills in python (and pytorch).&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;J. Duchi and H. Namkoong: Learning models with uniform performance via distributionally robust optimization. arXiv preprint arXiv:1810.08750 (2018)&lt;/li&gt;
&lt;li&gt;S. Sagawa et al.: Distributionally Robust Neural Networks, In Proc. ICLR (2020)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Out-of-distribution detection using contrastive training for medical imaging</title>
      <link>https://aim-lab.io/theses/oodd/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/oodd/</guid>
      <description>&lt;p&gt;Deep learning has revolutionized the field of medical imaging. However, the performance of a model drops when the distribution of the test data is different from the distribution of the training data. This is especially critical in a medical setting, where the amount of labelled training data is often limited, and in particular for the application in clinical routine, where the distribution of the test data cannot be controlled. The automatic detection of such Out-of-Distribution (OoD) samples at inference is important for the design of reliable models, but also to identify poor quality images and pathologies not seen during training.&lt;/p&gt;
&lt;p&gt;Recently, contrastive learning has shown to provide state-of-the-art results for OoD in image classification benchmarks [1]. Contrastive learning is an approach to formulate the task of finding similar and dissimilar samples during training. One advantage of the proposed method is that no OoD data is required during training.
The aim of this project is to explore OoD detection in deep learning in general, and in particular the use of contrastive training. The student will develop and implement (novel) methods for image classification, segmentation, and/or registration in a medical application.&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Prior experience and good understanding in machine learning and statistics.&lt;/li&gt;
&lt;li&gt;Very good programming skills in python (and pytorch).&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;J. Winkens et al.: Contrastive Training for Improved Out-of-Distribution Detection. arXiv preprint arXiv:2007.05566 (2020)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Privacy-preserving Deep Learning in Medical Imaging</title>
      <link>https://aim-lab.io/theses/ppml/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/ppml/</guid>
      <description>&lt;p&gt;Privacy-preserving artificial intelligence techniques such as differential privacy, encryption and multi-party computation can reconcile the needs for data utilisation and data protection in the medical domain, as mandated by legal and ethical requirements. Their widespread utilisation requires innovations in the fields of distributed machine learning (federated learning) as well as answering open questions in privacy research and cryptography.&lt;/p&gt;
&lt;p&gt;We are seeking an MSc candidate with a strong background in machine learning, preferrably with previous exposure to medical imaging topics to complete their thesis at our institute. Experience with distributed systems, privacy and security issues or cryptology is desirable.
We are offering an engaging work environment, a large, diverse team, close personal supervision and collaboration with AI, medical and privacy-preserving ML experts.&lt;/p&gt;
&lt;p&gt;We can accommodate a wide range of interests from your side! Please get in touch with us to find an appropriate topic. We are also able to supervise guided research projects, smaller in scope than full MSc theses.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Model-Based and Data-Driven Strategies in Medical Image Computing</title>
      <link>https://aim-lab.io/publication/proc-ieee-2020a/</link>
      <pubDate>Mon, 12 Oct 2020 12:39:15 +0200</pubDate>
      <guid>https://aim-lab.io/publication/proc-ieee-2020a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Secure, privacy-preserving and federated machine learning in medical imaging</title>
      <link>https://aim-lab.io/www.nature.com/articles/s42256-020-0186-1</link>
      <pubDate>Mon, 12 Oct 2020 06:59:15 +0200</pubDate>
      <guid>https://aim-lab.io/www.nature.com/articles/s42256-020-0186-1</guid>
      <description></description>
    </item>
    
    <item>
      <title>Impressum</title>
      <link>https://aim-lab.io/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>https://aim-lab.io/privacy/</guid>
      <description>&lt;h3&gt;Anschrift&lt;/h3&gt;
Technische Universität München &lt;br&gt;
Arcisstraße 21 &lt;br&gt;
80333 München &lt;br&gt;
Umsatzsteueridentifikationsnummer: DE811193231
&lt;h3&gt;Zuständige Aufsichtsbehörde&lt;/h3&gt;
Bayerisches Staatsministerium für Wissenschaft und Kunst
&lt;h3&gt;Inhaltlich verantwortlich&lt;/h3&gt;
Prof. Dr. Daniel Rückert&lt;br&gt;
Technische Universität München / Klinikum Rechts der Isar&lt;br&gt;
Lehrstuhl für Artificial Intelligence in Medicine and Healthcare&lt;br&gt;
TranslaTUM&lt;br&gt;
Einsteinstraße 25&lt;br&gt;
81675 München&lt;br&gt;
E-Mail: daniel(dot)rueckert(at)tum(dot)de&lt;br&gt;
&lt;h3&gt;Haftungshinweis&lt;/h3&gt;
&lt;p&gt;Trotz sorgfältiger inhaltlicher Kontrolle übernehmen wir keine Haftung für die Inhalte externer Links. Für den Inhalt der verlinkten Seiten sind ausschließlich deren Betreiber verantwortlich. Namentlich gekennzeichnete Beiträge in den Diskussionsbereichen geben die Meinung des Autors wieder. Für die Inhalte der Beiträge sind ausschließlich die Autoren zuständig.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A population-based phenome-wide association study of cardiac and aortic structure and function</title>
      <link>https://aim-lab.io/publication/nat-med-2020a/</link>
      <pubDate>Thu, 01 Jan 1970 01:33:40 +0100</pubDate>
      <guid>https://aim-lab.io/publication/nat-med-2020a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Genetic and functional insights into the fractal structure of the heart</title>
      <link>https://aim-lab.io/publication/nat-2020a/</link>
      <pubDate>Thu, 01 Jan 1970 01:33:40 +0100</pubDate>
      <guid>https://aim-lab.io/publication/nat-2020a/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
