<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Current Vacancies | AI in Medicine</title>
    <link>https://aim-lab.io/theses/</link>
      <atom:link href="https://aim-lab.io/theses/index.xml" rel="self" type="application/rss+xml" />
    <description>Current Vacancies</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Technical University of Munich 2023</copyright><lastBuildDate>Mon, 16 Oct 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://aim-lab.io/images/icon_hu90763c276d9f69c3ad22e431a6bb6670_11797_512x512_fill_lanczos_center_3.png</url>
      <title>Current Vacancies</title>
      <link>https://aim-lab.io/theses/</link>
    </image>
    
    <item>
      <title>IDP: iOS app for wearable health data management</title>
      <link>https://aim-lab.io/theses/florianhinterwimmer/idp_wearables/</link>
      <pubDate>Mon, 16 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/florianhinterwimmer/idp_wearables/</guid>
      <description>&lt;p&gt;​&lt;/p&gt;
&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;In an era where technology has seamlessly integrated with our day-to-day lives, health and fitness tracking has seen a revolutionary change. Gone are the days when we passively absorbed health information. Today, we&amp;rsquo;re in the age of data-driven insights, where personalized health data is not just recorded but actively analyzed to provide actionable insights.
​
In MeDecode we want to embody this evolution, we are a pre-registered startup founded six months ago by an active team of three co-founders, and we are currently seeking a student to contribute to the software development efforts to create a Minimal Viable Product. Offering users an intuitive platform to monitor, compare and understand various health metrics, this project truly stands apart with its emphasis on comparative insights against other users. In the vast sea of health data, understanding one&amp;rsquo;s metrics in isolation offers limited insight. Is a heart rate of 80 bpm at rest good or bad? How does a person&amp;rsquo;s sleep pattern compare with someone of their age and lifestyle? By allowing users to compare their data against that of others, we offer a clearer, contextualized view of their health. This not only bridges the gap between mere data collection and genuine understanding but also creates a more engaging and motivating user experience.
​
However, with the power of comparative insights comes a significant responsibility: ensuring user privacy and data anonymization. Firstly, it serves to protect user identity, ensuring that while data can be compared, individual identities remain concealed. Secondly, when users are aware that their data is anonymized, they are more inclined to report honestly, leading to more accurate and reliable comparative insights. Lastly, in the unfortunate event of a data breach, the anonymization of data drastically reduces its value to malicious actors, as it can&amp;rsquo;t be linked back to specific individuals, thereby minimizing potential harm.
&lt;br/&gt;
​&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications&lt;/h2&gt;
&lt;p&gt;​
We are actively seeking an enthusiastic Master&amp;rsquo;s student, preferably majoring in Computer Science, Information Systems, or Health Informatics. Your core responsibility will be to develop a simple iOS app that reads, saves and plots the HealthKit data. Your base of operations will be at the Institute for AI in Medicine, working closely with Doctors and Wearables Artificial Intelligence experts. It is our collective ambition to bring this project to the market, and we envision you playing a pivotal role.
​&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Strong motivation and interest in wearable technology, healthcare and/or artificial intelligence.&lt;/li&gt;
&lt;li&gt;Advanced programming skills in Swift (or preferred iOS programming language).&lt;/li&gt;
&lt;li&gt;Independent working style with strong interest in teamwork.
​
&lt;br/&gt;
​&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer&lt;/h2&gt;
&lt;p&gt;​&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An exciting  project in scope of a highly dynamic startup environment with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to the necessary hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of highly qualified computer scientists and medical experts.&lt;/li&gt;
&lt;li&gt;experiencing the development of an early stage tech/health startup&lt;/li&gt;
&lt;li&gt;potential for long-term engagment
​
&lt;br/&gt;
​&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply?&lt;/h2&gt;
&lt;p&gt;​
Send an email to &lt;a href=&#34;mailto:Contact@medecode.app&#34;&gt;Contact@medecode.app&lt;/a&gt; with your CV.
​
&lt;br/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Contrastive Learning and Generative Models for Cross-Domain Transfer Learning</title>
      <link>https://aim-lab.io/theses/johannespaetzold/diffusionformer/</link>
      <pubDate>Tue, 10 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/johannespaetzold/diffusionformer/</guid>
      <description>&lt;p&gt;In this Master thesis we aim to approach the cross-domain transfer learning problem with two powerful methods that help us to bridge the domain gap between source and target domain: contrastive learning [1] and generative models. Specifically, we want to solve the transfer learning problem for the computer vision task of graph extraction from images (e.g. road network extraction, blood-vessel network extraction, scene graph generation, or pose estimation) [2].&lt;/p&gt;
&lt;p&gt;To address these challenges, we propose two innovative strategies where one or ideally both can be explored during the course of the thesis:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Contrastive Learning for Domain Alignment [1]: Leveraging the power of contrastive learning, we seek to achieve domain alignment while harnessing label information from both domains.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Image-to-Image Translation with Generative Models: By exploring the capabilities of diffusion models [3] or GANs [4], we aim to generate target domain samples from source domain data.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both of these approaches will be applied to the Relationformer architecture, a unified one-stage transformer-based framework introduced in our recent ECCV paper [2]. Our experimentation will involve working with extensive biological datasets, such as whole brain vasculature [5], neurons, and satellite imagery.
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./tl_datasets.png&#34; alt=&#34;image datasets&#34;&gt;&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;p&gt;We are looking for a highly motivated Master’s student in Computer Science, Physics, Engineering or Mathematics. Your goal is to extend the existing Pytorch codebase and apply it to novel datasets. You will be working together with Johannes and Alex, two PostDocs scientist at TU Munich and Imperial College London under the supervision of Prof. Daniel Rückert. Importantly, we aim to publish the results of this work, with you, in a follow up study at a high-impact machine learning conference or in an academic journal.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Strong motivation and interest in machine learning.&lt;/li&gt;
&lt;li&gt;Advanced programming skills in C++, Python or C.&lt;/li&gt;
&lt;li&gt;Strong interest in teamwork and interdisciplinary research.&lt;/li&gt;
&lt;/ol&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of highly qualified experts in machine learning, computer vision, and deep learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Just send an email to &lt;a href=&#34;mailto:j.paetzold@ic.ac.uk&#34;&gt;j.paetzold@ic.ac.uk&lt;/a&gt; and &lt;a href=&#34;mailto:a.berger@tum.de&#34;&gt;a.berger@tum.de&lt;/a&gt;, with a short CV and your grade report. We promise to get back to you within days.&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;&lt;img src=&#34;./i2g.png&#34; alt=&#34;image image-to-graph&#34;&gt;&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;
&lt;p&gt;[1] Motiian, Saeid, et al. &amp;ldquo;Few-shot adversarial domain adaptation.&amp;rdquo; Advances in neural information processing systems 30 (2017).&lt;/p&gt;
&lt;p&gt;[2] Shit, Suprosanna, et al. &amp;ldquo;Relationformer: A unified framework for image-to-graph generation.&amp;rdquo; European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022.&lt;/p&gt;
&lt;p&gt;[3] Saharia, Chitwan, et al. &amp;ldquo;Palette: Image-to-image diffusion models.&amp;rdquo; ACM SIGGRAPH 2022 Conference Proceedings. 2022.&lt;/p&gt;
&lt;p&gt;[4] Liu, Ming-Yu, Thomas Breuel, and Jan Kautz. &amp;ldquo;Unsupervised image-to-image translation networks.&amp;rdquo; Advances in neural information processing systems 30 (2017).&lt;/p&gt;
&lt;p&gt;[5] Paetzold, Johannes C., et al. &amp;ldquo;Whole Brain Vessel Graphs: A Dataset and Benchmark for Graph Learning and Neuroscience.&amp;rdquo; Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2). 2021.
&lt;br/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis/Guided Research/IDP: Privacy-Preserving Synthetic Data Generation of Medical Tabular Records</title>
      <link>https://aim-lab.io/theses/florianhoelzl/privacy_synthetic_data/</link>
      <pubDate>Wed, 04 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/florianhoelzl/privacy_synthetic_data/</guid>
      <description>&lt;p&gt;Anonymizing data means removing or replacing any identifying information from a dataset, such as names or addresses. The aim of anonymization is to protect the privacy of individuals whose data is being collected and processed. However, anonymizing data is not sufficient to guarantee privacy protection. Research has shown that data samples can easily re-identified through a variety of approaches as simply as combining a dataset with other data sources, e.g. publicly available information [1]. This poses a problem for data sharing, especially in highly sensitive domains such as medicine.&lt;/p&gt;
&lt;p&gt;Synthetic data allows to generate new examples that preserve the statistical properties of the original data [2]. In a medical use case, synthetic data could be used to generate realistic but entirely artificial medical records. These synthetic medical records can be used for a variety of different purposes, such as augmenting existing datasets or sharing data without revealing any patient information [3].&lt;/p&gt;
&lt;p&gt;For the later, however, synthetic data doesn&amp;rsquo;t per se protect the privacy of individual patients. To achieve privacy preservation, we have to apply additional techniques such as differential privacy [4]. The aim of this project is to evaluate synthetic data generation with differential privacy for tabular medical records. You will first evaluate current literature of synthetic data generation for tabular data with regards to medical records [5, 6]. In the following, a data generation pipeline will be implemented and analysed to evaluate the performance of existing synthetisation approaches on a real-world multiple sclerosis dataset. The data will be used to predict disease activity and help treatment decision making for disease-modifying therapies [7]. To measure the prediction capabilities of the synthetically generated private data, its prediction performance is compared against existing baselines from the original data curated during different time intervals. Furthermore, the addition of synthetic data into the existing training process for increased model robustness will be assessed. This project will help to evaluate the ability of synthetic data to enable data sharing in a privacy preserving manner and additionally its potential benefits for increasing model robustness due to data augmentation.
&lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications&lt;/h2&gt;
&lt;p&gt;We are looking for a highly motivated Master&amp;rsquo;s student in Computer Science, Physics, Engineering or Mathematics. You will establish a comprehensive pipeline in PyTorch or JAX to generate and evaluate synthetic data from a real world medical dataset under differential privacy. You will be working at the institute for AI in Medicine, at the Privacy-Preserving and Trustworthy Machine Learning Group. Importantly, we aim to publish the results of this work, with you, in a follow up study at a high-impact deep learning conference or in an academic journal.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Strong motivation and interest in deep learning and generative neural networks.&lt;/li&gt;
&lt;li&gt;Advanced programming skills in Python and a common DL framework (PyTorch, Tensorflow, JAX).&lt;/li&gt;
&lt;li&gt;Independent working style with strong interest in teamwork.&lt;/li&gt;
&lt;/ol&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting state-of-the-art research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to the necessary computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of highly qualified experts in machine and deep learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Narayanan and Shmatikov (2006). How to Break Anonymity of the Netflix Prize Dataset. ArXiv, cs/0610105. &lt;/br&gt;
[2] Jordon et al. (2022). Synthetic Data - what, why and how? ArXiv, abs/2205.03257. &lt;/br&gt;
[3] Chen et al. (2021). Synthetic Data in Machine Learning for Medicine and Healthcare. Nature Biomedical Engineering 2021. &lt;/br&gt;
[4] Abadi et al. (2016). Deep Learning with Differential Privacy. ACM SIGSAC 2016. &lt;/br&gt;
[5] Jordon et al. (2018). PATE-GAN. ICLR 2018. &lt;/br&gt;
[6] Lee et al. (2022). Differentially Private Normalization Flows for Synthetic Tabular Data Generation. AAAI 2022. &lt;/br&gt;
[7] Braune et al. (2022). PHREND®—A Real-World Data-Driven Tool Supporting Clinical Decisions to Optimize Treatment in Relapsing-Remitting Multiple Sclerosis. Frontiers in Digital Health 03.2022.&lt;/p&gt;
</description>
    </item>
    

    
    <item>
      <title>MSc Thesis: Learning High-Resolution ECG Representations for Cardiac Health Analysis</title>
      <link>https://aim-lab.io/theses/oezguenturgut/highres_ecg_representations/</link>
      <pubDate>Mon, 28 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/oezguenturgut/highres_ecg_representations/</guid>
      <description>&lt;p&gt;Examinations with expensive cardiac magnetic resonance (CMR) imaging provide detailed structural information of the heart as it cycles at least one heartbeat. Since the dynamics of the heart are important for analysing cardiac health, CMR imaging is the gold-standard for evidence-based diagnosis of cardiovascular diseases (leading causes of death globvally [1]). However, long scan times and high costs limit its use in clinical practice. In this project, we aim to adress this issue by enabling cardiac health analysis using cost-effective and widely available electrocardiograms (ECG) only. The objective is to learn cardiac representations with high temporal resolution from ECG, with a focus on capturing the dynamics of a single heartbeat.&lt;/p&gt;
&lt;p&gt;Similar to previous works [2], we propose the integration of spatiotemporal information from CMR imaging into the representation learning process, enhancing the interpretation of ECG data. Contrastive learning techniques [3] should be leveraged to transfer information from CMR imaging to high-resolution ECG representations of a single heartbeat. To this end, strategies to extract a representative heartbeat from ECG recordings have to be investigated, considering the variation in heartbeat length within a recording. Furthermore, techniques to synchronise cardiac cycles between ECG and CMR imaging data have to be developed, accounting for the temporal offset in data acquisition.&lt;/p&gt;
&lt;p&gt;We will evaluate the strength of our approach on multiple downstream tasks, including the classification of various cardiovascular diseases and regression of cardiac phenotypes solely from ECG data. Experiments on paired ECG and CMR imaging data of 40k subjects provided by the UK Biobank population study are conducted within this work.
&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Advanced programming skills in Python and PyTorch.&lt;/li&gt;
&lt;li&gt;Strong analytical and problem-solving skills, particularly in working with complex and multimodal datasets.&lt;/li&gt;
&lt;li&gt;Excellent communication skills to document and present research findings effectively.
&lt;br/&gt;&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The chance to work with an experienced team of data scientists and medical experts.&lt;/li&gt;
&lt;li&gt;Close supervision with regular meetings to provide guidance and feedback.&lt;/li&gt;
&lt;li&gt;An opportunity to collaborate on challenging aspects of a clinical research project.
&lt;br/&gt;&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Please send an e-mail with your CV and grade report to &lt;a href=&#34;mailto:oezguen.turgut@tum.de&#34;&gt;oezguen.turgut@tum.de&lt;/a&gt;.
&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The top 10 causes of death (World Health Organization)&lt;/a&gt; &lt;br/&gt;
[2] &lt;a href=&#34;https://arxiv.org/abs/2308.05764&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI&lt;/a&gt; &lt;br/&gt;
[3] &lt;a href=&#34;https://arxiv.org/abs/2002.05709&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Simple Framework for Contrastive Learning of Visual Representations&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>IDP/Thesis: Physics-based deep learning for hyperspectral brain surgery imaging</title>
      <link>https://aim-lab.io/theses/ivanezhov/hsi_transfer_md/</link>
      <pubDate>Thu, 27 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/ivanezhov/hsi_transfer_md/</guid>
      <description>&lt;p&gt;Hyperspectral imaging (HSI) is an optical technique that processes the electromagnetic spectrum at a multitude of monochromatic, adjacent frequency bands. The wide-bandwidth spectral signature of a target object&amp;rsquo;s reflectance allows fingerprinting its physical, biochemical, and physiological properties. HSI has been applied for various applications, such as remote sensing and biological tissue analysis. Recently, HSI was also used to differentiate between healthy and pathological tissue under operative conditions in a surgery room on patients diagnosed with brain tumors [1].&lt;/p&gt;
&lt;p&gt;Within the &lt;a href=&#34;https://hyperprobe.eu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HyperProbe&lt;/a&gt; project, we aim to develop a novel all-optical, AI-powered intraoperative imaging system to transform monitoring of brain tumour surgery. 
Your goal would be to develop a methodology at the intersection between physics and machine-learning to identify biomarkers of healthy and tumor brain tissue.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hyperprobe.eu/wp-content/uploads/2022/12/shutterstock_1152709331-2048x1152.jpg&#34; alt=&#34;Surgery&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Enthusiasm for merging physics with AI for developing new biomedical imaging modality&lt;/li&gt;
&lt;li&gt;Ideally, prior work experience using deep learning for image processing&lt;/li&gt;
&lt;li&gt;Decent programming skills in Python as well as PyTorch or Tensorflow&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project aimed to build a new imaging modality that has a potential to change the neurosurgery monitoring in the near future&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Send an email to &lt;a href=&#34;mailto:ivan.ezhov@tum.de&#34;&gt;ivan.ezhov@tum.de&lt;/a&gt; with your CV and transcript.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Luca Giannoni, Frédéric Lange and Ilias Tachtsidis. Hyperspectral imaging solutions for brain tissue
metabolic and hemodynamic monitoring: past, current and future developments, J. Opt. 20 (2018)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Multi-Organ Self-Supervised Learning for Efficient Exploitation of Large-Scale (1 million&#43;) Real World Clinical Radiograph Dataset</title>
      <link>https://aim-lab.io/theses/paulhager/multi_organ_self_supervised/</link>
      <pubDate>Thu, 27 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/paulhager/multi_organ_self_supervised/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;As the availability of large clinical datasets continues to grow, the cost and effort associated with manual labeling of medical images become a significant bottleneck in leveraging the full potential of these data. In this research thesis, we aim to investigate the importance of self-supervised learning techniques in harnessing large clinical datasets, where labels are expensive and scarce. Specifically, we explore two prominent self-supervised deep learning approaches: contrastive learning and masked autoencoders.&lt;/p&gt;
&lt;p&gt;Contrastive learning [1] has gained considerable attention due to its ability to learn useful representations without requiring labeled data. However, in the context of large clinical datasets comprising radiography images of multiple anatomical regions, several challenges arise. The need for downsampling to achieve viable batch sizes, coupled with the focus on global features, might limit the effectiveness of contrastive learning, particularly for capturing fine-grained features and retaining the high-resolution information of the images.&lt;/p&gt;
&lt;p&gt;To overcome these limitations, we propose the utilization of masked autoencoders [2], an alternative self-supervised learning technique, for generating strong embeddings from our extensive in-house clinical dataset consisting of over 1 million radiography images across multiple anatomical regions. Masked autoencoders excel at capturing intricate details and preserving fine-grained features due to their ability to reconstruct input data by reconstructing masked portions. This characteristic makes them well-suited for large image sizes and enables them to emphasize local, region-specific information.&lt;/p&gt;
&lt;p&gt;We will evaluate the strength of our embeddings through multiple downstream tasks such as foreign object identification, bone fracture classification, and fracture detection (bounding boxes). We will use a combination of NLP and expert annotations to develop a large enough training dataset for efficient finetuning using minimal labeled data.&lt;/p&gt;
&lt;h2 id=&#34;to-accomplish-this-work-successfully-we-expect-you-to-have&#34;&gt;To accomplish this work successfully, we expect you to have:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Strong coding skills and familiarity with Pytorch&lt;/li&gt;
&lt;li&gt;Basic knowledge of self-supervised methods such as contrastive learning or MAEs&lt;/li&gt;
&lt;li&gt;A strong spirit of independent work and desire to solve interesting, realworld research questions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Access to a massive inhouse dataset of over 1 million medical images&lt;/li&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine.&lt;/li&gt;
&lt;li&gt;Support in bringing your finished project to publication&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://arxiv.org/pdf/2002.05709.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Simple Framework for Contrastive Learning of Visual Representations&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://arxiv.org/abs/2111.06377&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Masked Autoencoders Are Scalable Vision Learners&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Send an email to &lt;a href=&#34;mailto:paul.hager@tum.de&#34;&gt;paul.hager@tum.de&lt;/a&gt; with your CV and transcript. We promise to get back to you within a couple of days.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Practical Course: Applied Deep Learning in Medicine</title>
      <link>https://aim-lab.io/theses/alexziller/practical/</link>
      <pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/alexziller/practical/</guid>
      <description>&lt;p&gt;In this course students are given the chance to apply their abilities and knowledge in deep learning to real-world medical data. Students will be assigned a medical dataset and in close consultation with medical doctors create a project plan. Deep Learning methods will be applied to solve tasks to achieve the goal that is agreed upon. Datasets will be explored and analysed in several directions and different approaches will be evaluated and compared.
In short this course offers students to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apply Deep Learning in the real world&lt;/li&gt;
&lt;li&gt;Work on medical data and potentially help diagnose and analyse health related problems&lt;/li&gt;
&lt;li&gt;Close supervision by PhD students with specialization in AI&lt;/li&gt;
&lt;li&gt;Collaboration with medical experts&lt;/li&gt;
&lt;li&gt;Work on the intersection between medicine and computer science&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Completed at least one or several machine learning or deep learning courses (e.g. Intro to Deep Learning, Advanced Deep Learning, Machine Learning etc) with good grades. Knowledge about augmentation, optimizer, common model architectures, etc.&lt;/li&gt;
&lt;li&gt;Good coding skills in python&lt;/li&gt;
&lt;li&gt;Coding experience in one or more deep learning frameworks (Tensorflow, PyTorch, etc)&lt;/li&gt;
&lt;li&gt;Enthusiasm for the application in the medical field&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;objectives&#34;&gt;Objectives:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ability to tackle applied deep learning projects in a structured manner with a good overview of possibilities&lt;/li&gt;
&lt;li&gt;Gained insight into the problems of medical data&lt;/li&gt;
&lt;li&gt;Final outcome as a useful insight or tool for medical professionals&lt;/li&gt;
&lt;li&gt;If possible outcome will be published in a peer-reviewed venue&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Students will work in teams of three&lt;/li&gt;
&lt;li&gt;Each group will be assigned one medical dataset&lt;/li&gt;
&lt;li&gt;(Bi)weekly meetings with progress reports&lt;/li&gt;
&lt;li&gt;Final presentation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminary-meeting&#34;&gt;Preliminary meeting&lt;/h2&gt;
&lt;p&gt;A preliminary meeting will take place on 12th of July, 2023 at 10:00 on zoom with the following details: &lt;br&gt;
&lt;a href=&#34;https://tum-conf.zoom.us/j/69075883519&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tum-conf.zoom.us/j/69075883519&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Meeting ID: 690 7588 3519 &lt;br&gt;
Passcode: 850155&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;PracticalPreMeetingWiSe2324.pdf&#34;&gt;Slides - WS 2023/24&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;PracticalPreMeetingSoSe23.pdf&#34;&gt;(Outdated) Slides - SoSe 2023&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;PracticalPreMeetingWS22.pdf&#34;&gt;(Outdated) Slides - WS 2022/23&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;PracticalPreMeeting.pdf&#34;&gt;(Outdated) Slides - SoSe 2022&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Prediction of Points-of-Interest on CT Vertebrae</title>
      <link>https://aim-lab.io/theses/hendrikmoeller/poi_prediction/</link>
      <pubDate>Fri, 12 May 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/hendrikmoeller/poi_prediction/</guid>
      <description>&lt;p&gt;The position of attachment points of ligaments and muscles on vertebral bodies are crucial for biomechanical simulations.&lt;/p&gt;
&lt;p&gt;Your task would be to compare existing methods and develop a model to accurately predict these points onto given vertebrae. The task is similar to Landmark prediction (&lt;a href=&#34;https://paperswithcode.com/task/facial-landmark-detection/latest%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://paperswithcode.com/task/facial-landmark-detection/latest)&lt;/a&gt;, which is used in deep-fake, for example.&lt;/p&gt;
&lt;p&gt;You will be working with 3D CT images and segmentations. You are given a hand-made Ground-Truth for the points as well as a prediction of points using registration with some selected &amp;ldquo;known-goods&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;The tasks are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using the registrated data, make a preselection of the dataset.&lt;/li&gt;
&lt;li&gt;Make a first baseline approach using the registrated data/points.&lt;/li&gt;
&lt;li&gt;After a initial research phase, develop and train a DL model to outperform the registration approach.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Later steps could involve using the predicted POIs to measure the form of the vertebrae, i.e. for fracture detection.&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your Qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Most important: solid coding skills and familiarity with PyTorch and Numpy&lt;/li&gt;
&lt;li&gt;Strong background in machine learning&lt;/li&gt;
&lt;li&gt;Motivated master student in Informatics, Mathematics, or a closely related field&lt;/li&gt;
&lt;li&gt;Ability to thoroughly answer a research question&lt;/li&gt;
&lt;li&gt;Strong research mindset&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to Apply&lt;/h2&gt;
&lt;p&gt;Send an email to &lt;a href=&#34;mailto:hendrik.moeller@tum.de&#34;&gt;hendrik.moeller@tum.de&lt;/a&gt;, with a short CV and your grade report. We promise to get back to you within days.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Bias and Fairness in Healthcare AI-based Algorithms</title>
      <link>https://aim-lab.io/theses/haifabeji/bias_fairness_ai_healthcare/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/haifabeji/bias_fairness_ai_healthcare/</guid>
      <description>&lt;p&gt;We are looking for a motivated Master&amp;rsquo;s student to join our research team and work on a thesis project that deals with bias in healthcare, specifically with AI-based algorithms. The successful candidate will have access to a large-scale biomedical database and research resource, containing in-depth genetic and health information from half a million participants. The position involves designing a use case for evaluating bias, implementing machine learning models, and generating a fairness report.&lt;/p&gt;
&lt;p&gt;This is an exciting opportunity for a motivated Master&amp;rsquo;s student to work on a project with real-world implications for healthcare. Additionally, there may be the possibility of publishing the results of the project in a peer-reviewed scientific journal, providing an excellent opportunity to showcase the student&amp;rsquo;s research skills and contribute to the field of healthcare AI-based algorithms.&lt;/p&gt;
&lt;h2 id=&#34;project-background&#34;&gt;Project Background:&lt;/h2&gt;
&lt;p&gt;Healthcare AI-based algorithms are rapidly becoming ubiquitous in medical settings, from assisting clinicians in diagnosing diseases to personalizing treatments. While AI has the potential to revolutionize healthcare, it can also perpetuate biases and lead to disparities in care. For example, an AI-based algorithm may have a higher accuracy rate for diagnosing certain diseases in specific racial or ethnic groups, leading to differential treatment and outcomes. Bias in healthcare AI-based algorithms can have serious consequences for patient care, particularly for those from marginalized or underrepresented groups.
Given the importance of fair and equitable healthcare, it is crucial to incorporate fairness checks into the design and implementation of healthcare AI-based algorithms. Fairness checks can help identify and mitigate bias and ensure that the algorithm does not unfairly discriminate against any group. The successful candidate will be responsible for designing and implementing a use case that evaluates bias in healthcare AI-based algorithms and generating a fairness report.&lt;/p&gt;
&lt;h2 id=&#34;your-responsibilities&#34;&gt;Your Responsibilities:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Design a use case for evaluating bias in healthcare AI-based algorithms&lt;/li&gt;
&lt;li&gt;Implement machine learning models to test the use case&lt;/li&gt;
&lt;li&gt;Generate a fairness report that identifies any bias and suggests ways to mitigate it&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your Qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Strong programming skills in Python&lt;/li&gt;
&lt;li&gt;Experience with machine learning algorithms and data analysis&lt;/li&gt;
&lt;li&gt;Excellent written and verbal communication skills&lt;/li&gt;
&lt;li&gt;Ability to work independently and as part of a team&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to Apply&lt;/h2&gt;
&lt;p&gt;Fill-in the following &lt;a href=&#34;https://forms.gle/bZQamy5btyYWdUbv6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;form&lt;/a&gt; or send an email to &lt;a href=&#34;mailto:haifa.beji@tum.de&#34;&gt;haifa.beji@tum.de&lt;/a&gt; with your CV. We promise to get back to you within days.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Spatiotemporal Contrastive Learning of Progressive Diseases</title>
      <link>https://aim-lab.io/theses/paulhager/temporal_contrastive_learning/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/paulhager/temporal_contrastive_learning/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Contrastive learning is currently the most effective way to learn representations in a self-supervised manner. Its strength lies in training networks to solve a context-matching task using multiple views of an image. If the views are smartly chosen through proper augmentations, the model learns informative representations of data without any human supervision. These representations can then be used on targeted downstream tasks.&lt;/p&gt;
&lt;p&gt;Contrastive learning has been explored extensively in the natural image domain but there still remain many unanswered questions and untapped potential in the medical domain. The unique characteristics of medical data offers many avenues to explore to try and determine how best to adapt contrastive learning to medical imaging. In this project, we are interested in the temporal dimension in two very large medical datasets.&lt;/p&gt;
&lt;p&gt;Our main application will be for learning representations of the evolution of progressive diseases. Despite being the leading cause of blindness in the elderly, little is understood about how Age-related macular degeneration (AMD) develops over time. This evolution is documented in our dataset of 181k retinal images of 7.5k subjects imaged over eight years. Using the self-supervised  methodology you develop, you will also learn representations that encode multiple years of disease progression, ultimately improving diagnosis and prognosis of AMD.&lt;/p&gt;
&lt;p&gt;A secondary application, to test the generalisability of the method, is cardiac MR imaging. Here we will train models to learn the dynamics of the heart as it cycles at least one heart beat, which is important for predicting cardiac disease such as infarction. The full cycle cardiac MR data from the UKBB contains over 45k subjects.&lt;/p&gt;
&lt;h2 id=&#34;to-accomplish-this-work-successfully-we-expect-you-to-have&#34;&gt;To accomplish this work successfully, we expect you to have:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Strong coding skills and familiarity with Pytorch&lt;/li&gt;
&lt;li&gt;Basic knowledge of contrastive learning&lt;/li&gt;
&lt;li&gt;A strong spirit of independent work and desire to solve interesting research questions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine.&lt;/li&gt;
&lt;li&gt;Support in bringing your finished project to publication&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://arxiv.org/pdf/2002.05709.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Simple Framework for Contrastive Learning of Visual Representations&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://arxiv.org/pdf/2104.14558.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href=&#34;https://faculty.ucmerced.edu/mhyang/papers/cvpr2021_cvrl.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spatiotemporal Contrastive Video Representation Learning&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Send an email to &lt;a href=&#34;mailto:robert.holland15@imperial.ac.uk&#34;&gt;robert.holland15@imperial.ac.uk&lt;/a&gt; and &lt;a href=&#34;mailto:paul.hager@tum.de&#34;&gt;paul.hager@tum.de&lt;/a&gt; with your CV and transcript. We promise to get back to you within a couple of days.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Diffusion model for Graph Generation</title>
      <link>https://aim-lab.io/theses/johannespaetzold/masther_thesis_relationformer/</link>
      <pubDate>Mon, 03 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/johannespaetzold/masther_thesis_relationformer/</guid>
      <description>&lt;p&gt;In this Master thesis we aim to address the graph extraction problem using a new powerful class of neural networks - Diffusion [2]. A comprehensive representation of an image requires understanding objects and their mutual relationship, especially in image-to-graph generation, e.g., road network extraction, blood-vessel network extraction, or scene graph generation. 
Traditionally, image-to-graph generation is addressed with a two-stage approach consisting of object detection followed by a separate relation prediction, which prevents simultaneous object-relation interaction. In our recent ECCV paper, we proposed a unified one-stage transformer-based framework, namely &lt;em&gt;Relationformer&lt;/em&gt; that jointly predicts objects and their relations [1].&lt;/p&gt;
&lt;p&gt;Our applications will be large scale biological applications for example the whole brain vasculature [3] or neurons as well as satellite imagery.&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;&lt;img src=&#34;./relationformer.png&#34; alt=&#34;image transformer&#34;&gt;&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;p&gt;We are looking for a highly motivated Master’s student in Computer Science, Physics, Engineering or Mathematics. Your goal is to extend the existing Pytorch codebase and apply it to novel datasets. You will be working together with Suprosanna and Johannes, two PostDocs scientist at TU Munich and Imperial College London under the supervision of Prof. Daniel Rückert. Importantly, we aim to publish the results of this work, with you, in a follow up study at a high-impact machine learning conference or in an academic journal.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Strong motivation and interest in machine learning.&lt;/li&gt;
&lt;li&gt;Advanced programming skills in C++, Python or C.&lt;/li&gt;
&lt;li&gt;Strong interest in teamwork and interdisciplinary research.&lt;/li&gt;
&lt;/ol&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of highly qualified experts in machine learning, computer vision and deep learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Just send an email to &lt;a href=&#34;mailto:suprosanna.shit@tum.de&#34;&gt;suprosanna.shit@tum.de&lt;/a&gt; and &lt;a href=&#34;mailto:j.paetzold@ic.ac.uk&#34;&gt;j.paetzold@ic.ac.uk&lt;/a&gt;, with a short CV and your grade report. We promise to get back to you within days.&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;&lt;img src=&#34;./vessels.png&#34; alt=&#34;image vessel&#34;&gt;&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;
&lt;p&gt;[1] Shit, Suprosanna, et al. &amp;ldquo;Relationformer: A Unified Framework for Image-to-Graph Generation.&amp;rdquo;, &lt;a href=&#34;https://arxiv.org/abs/2203.10202&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2203.10202&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] Chen et al. &amp;ldquo;DiffusionDet: Diffusion Model for Object Detection.&amp;rdquo;, &lt;a href=&#34;https://arxiv.org/pdf/2211.09788.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/2211.09788.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] Paetzold, Johannes C., et al. &amp;ldquo;Whole Brain Vessel Graphs: A Dataset and Benchmark for Graph Learning and Neuroscience.&amp;rdquo; Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2). 2021.
&lt;br/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Automatic recognition of billing codes based on dental documentation using Artificial Intelligence</title>
      <link>https://aim-lab.io/theses/danielrueckert/boryschibisov/</link>
      <pubDate>Tue, 21 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/danielrueckert/boryschibisov/</guid>
      <description>&lt;p&gt;We are an international team of experts in the field of NLP and AI looking for a highly motivated Master&amp;rsquo;s student to join us for a master thesis project. Our main focus is the development of Doctos, an app that generates dental documentation through speech-to-text and converts the documentation into relevant billing codes using Named Entity Recognition. The documentation and the generated billing codes are automatically imported into the relevant PVS.
The objective of this thesis is to compare different methods for automatic recognition of billing codes from dental documentation. In particular, the focus will be on Named Entity Recognition techniques and their implementation in Doctos.&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Computer Science, Mathematics or similar background&lt;/li&gt;
&lt;li&gt;Strong background in NLP and machine learning&lt;/li&gt;
&lt;li&gt;Interest in medical documentation and healthcare technology&lt;/li&gt;
&lt;li&gt;Proficient in Python&lt;/li&gt;
&lt;li&gt;Experience with Huggingface and NLP frameworks such as PyTorch, Tensorflow, or Keras (optional)&lt;/li&gt;
&lt;li&gt;Fluent in German&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A close, personal supervision&lt;/li&gt;
&lt;li&gt;A unique opportunity to work in an interdisciplinary team and contribute to the development of Doctos&lt;/li&gt;
&lt;li&gt;Access to cutting-edge technologies and techniques in NLP and AI&lt;/li&gt;
&lt;li&gt;A unique opportunity to contribute to the development of a game-changing app in the healthcare industry.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are interested in this opportunity, please get in touch with us to discuss further details and to find an individual topic! This project is in collaboration with Doctos and under supervision of Bory Chibisov (&lt;a href=&#34;mailto:bc@doctos.de&#34;&gt;bc@doctos.de&lt;/a&gt;) and Prof. Pförringer.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: transfer learning for segmentation of tubular structures in thoracic CT images</title>
      <link>https://aim-lab.io/theses/martinmenten/thoracic_ct_processing/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/martinmenten/thoracic_ct_processing/</guid>
      <description>&lt;p&gt;Computed tomography (CT) scans are commonly used in clinic practice to diagnose and monitor diseases of the lung, heart and upper abdomen [1]. Deep learning has seen wide-spread application for the segmentation of organs in CT images [2,3]. However, its use for segmentation of complex, tubular structures, such as the bronchial proximal airways or cardiac vasculature, has been inhibited by a lack of high-quality ground truth labels [4]. In this research project, the prospective student will investigate the use of unsupervised learning and transfer learning to segment complex structures in chest CT images without having to rely on large amounts of ground truth annotations.&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Enthusiasm for deep learning and biomedical imaging.&lt;/li&gt;
&lt;li&gt;Advanced knowledge of machine learning and computer vision. Ideally, prior work experience using deep learning for image processing.&lt;/li&gt;
&lt;li&gt;Excellent programming skills in Python as well as PyTorch or Tensorflow.&lt;/li&gt;
&lt;li&gt;Full time commitment towards the completion of your Master&amp;rsquo;s project.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Send an email to &lt;a href=&#34;mailto:martin.menten@tum.de&#34;&gt;martin.menten@tum.de&lt;/a&gt; and &lt;a href=&#34;mailto:veronika.zimmer@tum.de&#34;&gt;veronika.zimmer@tum.de&lt;/a&gt; with your CV and transcript. We aim to get back to you within a couple of days.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Grainger, Ronald G., and David J. Allison, eds. Grainger &amp;amp; Allison&amp;rsquo;s diagnostic radiology: a textbook of medical imaging. Vol. 1. Churchill Livingstone, 1997.&lt;br&gt;
[2] Dong, Xue, et al. &amp;ldquo;Automatic multiorgan segmentation in thorax CT images using U‐net‐GAN.&amp;rdquo; Medical physics 46.5 (2019): 2157-2168.&lt;br&gt;
[3] Wasserthal, Jakob, et al. &amp;ldquo;TotalSegmentator: robust segmentation of 104 anatomical structures in CT images.&amp;rdquo; arXiv preprint arXiv:2208.05868 (2022).&lt;br&gt;
[4] Willemink, Martin J., et al. &amp;ldquo;Preparing medical imaging data for machine learning.&amp;rdquo; Radiology 295.1 (2020): 4-15.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Scaling Laws of Equivariant Convolutions</title>
      <link>https://aim-lab.io/theses/florianhoelzl/scaling_laws/</link>
      <pubDate>Wed, 21 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/florianhoelzl/scaling_laws/</guid>
      <description>&lt;p&gt;Equivariant convolutions are a novel approach that incorporate additional geometric properties of the input domain during the convolution process (i.e. symmetry properties such as rotations and reflections) [1]. This additional inductive bias allows the model to learn more robust and general features from less data, rendering them highly promising for application in the medical domain. So far, however, nobody has investigated how their beneficial characteristics impact the design and scaling of deep learning model architectures.&lt;/p&gt;
&lt;p&gt;We have developed a framework for initial investigation of equivariant convolutions and now want to evaluate how their performance can be further increased with larger model sizes and under different training regimes. This work plans to build onto previous highly impactful research on model design, such as the establishment of the EfficientNet architecture and the Chinchilla language model, to create a sound basis for the further consolidation of equivariant convolutions in the broader research landscape [2, 3]. The focus will be to thoroughly analyze and expand a framework for equivariant models already developed at our lab. This includes getting familiar with model architectures in general, the properties of equivariant convolutions and the intersection of the two. Our goal is to develop a methodological framework for equivariant model architectures that can be easily adapted to the properties of the used dataset and are able to beat state-of-the-art non-equivariant alternatives in standard and privacy-preserving deep learning settings [4].
&lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;p&gt;We are looking for a highly motivated Master’s student in Computer Science, Physics, Engineering or Mathematics. You will establish a comprehensive pipeline in PyTorch or JAX to evaluate the properties of equivariant models on different benchmark datasets. You will be working at the institute for AI in Medicine, at the Privacy-Preserving and Trustworthy Machine Learning Group. Importantly, we aim to publish the results of this work, with you, in a follow up study at a high-impact deep learning conference or in an academic journal.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Strong motivation and interest in deep learning and learning theory.&lt;/li&gt;
&lt;li&gt;Advanced programming skills in Python and a common DL framework (PyTorch, Tensorflow, JAX).&lt;/li&gt;
&lt;li&gt;Independent working style with strong interest in teamwork and methodic research.&lt;/li&gt;
&lt;/ol&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting state-of-the-art research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to the necessary computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of highly qualified experts in image processing, computer vision and deep learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Cohen and Welling (2016). Group Equivariant Convolutions. ICML 2016. &lt;/br&gt;
[2] Tan and Le (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. ICML 2019. &lt;/br&gt;
[3] Hoffmann et al. (2022). Training Compute-Optimal Large Language Models. ArXiv, abs/2203.15556. &lt;/br&gt;
[4] Abadi et al. (2016). Deep Learning with Differential Privacy. ACM SIGSAC 2016.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis/Guided Research/IDP: Efficient Training under Differential Privacy</title>
      <link>https://aim-lab.io/theses/florianhoelzl/efficient_training/</link>
      <pubDate>Wed, 21 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/florianhoelzl/efficient_training/</guid>
      <description>&lt;p&gt;Differential privacy (DP) is the gold standard of privacy-preserving deep learning and has seen increasing interest in the last few years, especially in the medical domain, where the protection of sensitive data is of highest interest [1]. Privacy in deep learning, however, still comes at a high privacy-utility trade-off that restricts the practical usability of models trained under DP. We, as researchers, try to solve this issue by looking into learning theory and by developing novel approaches that allow DP networks to challenge non-private approaches in clinical application.&lt;/p&gt;
&lt;p&gt;Two properties that affect all differentially private networks are model size and the chosen privacy parameters during training. In this work, we plan to analyze these two areas and introduce changes to the training regime, that improve not only the performance of the models but also reduce their computational overhead. The goal is to 1) build on top of research done on learning sparse neural networks and correspondingly adapt the model parameters during training [2]. And 2), we look at the amount of total noise added during training with DP and evaluate, how to adapt the corresponding privacy parameters without any knowledge about the model or dataset [3]. If successful, this research can be applied to any differential private model in a plug-and-play fashion during training to further reduce the privacy-utility trade-off.
&lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;p&gt;We are looking for a highly motivated Master’s student in Computer Science, Physics, Engineering or Mathematics. You will establish a comprehensive pipeline in PyTorch or JAX to evaluate the model sparsity and changing privacy-parameters on different benchmark datasets for models trained under DP. You will be working at the institute for AI in Medicine, at the Privacy-Preserving and Trustworthy Machine Learning Group. Importantly, we aim to publish the results of this work, with you, in a follow up study at a high-impact deep learning conference or in an academic journal.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Strong motivation and interest in deep learning and learning theory.&lt;/li&gt;
&lt;li&gt;Advanced programming skills in Python and a common DL framework (PyTorch, Tensorflow, JAX).&lt;/li&gt;
&lt;li&gt;Independent working style with strong interest in teamwork and methodic research.&lt;/li&gt;
&lt;/ol&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting state-of-the-art research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to the necessary computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of highly qualified experts in image processing, computer vision and deep learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Abadi et al. (2016). Deep Learning with Differential Privacy. ACM SIGSAC 2016. &lt;/br&gt;
[2] Louizos et al. (2018). Learning sparse neural networks through L0 regularization. ICLR 2018. &lt;/br&gt;
[3] Sander et al. (2022). TAN without a burn: Scaling Laws of DP-SGD. ArXiv, abs/2210.03403.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: An attention-based image denoising network leveraging information of both spatial and frequency domain</title>
      <link>https://aim-lab.io/theses/jiazhenpan/denosing/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/jiazhenpan/denosing/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Image denoising task, in which a clean image is recovered from a noise observation, is a classical inverse problem and still active topic in low-level vision since it is an indispensable step in many practical applications. In past decades, a large variety of image denoising methods employing neural networks were proposed to solve this inverse problem. These methods are major in the spatial domain which denoise the image straightforwardly by extracting the spatial information using the sliding CNN window. On the other hand, image denoising from the frequency domain also has a long history in which the low-pass filter techniques are applied and the noise (major in high-frequency space) can be filtered out. The denoising optimization in the frequency domain is frequently utilized in medical image reconstruction. Recently a great number of frequency networks with CNNs are used in this field to improve the reconstruction quality. However, this approach is rarely studied in the nature denoising field with RGB images. More recently, the advent of Transformers evolutes the computer vision field. Its inherent attributes like larger receptive field and lower inductive bias facilitate the image denoising tasks.
In this work, we attempt to introduce a hybrid image denoising network that optimizes the noise image from both spatial and frequency domain. A comparison with SOTA methods on public datasets like urban100 or SIDD will be conducted in the end.&lt;/p&gt;
&lt;h2 id=&#34;to-accomplish-this-work-successfully-we-expect-you-have&#34;&gt;To accomplish this work successfully, we expect you have:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Most important: solid coding skills and familiarity with Pytorch and Numpy&lt;/li&gt;
&lt;li&gt;Knowledge of the state-of-the-art image denoising methods&lt;/li&gt;
&lt;li&gt;Knowledge of the state-of-the-art CNN and Transformer approaches&lt;/li&gt;
&lt;li&gt;Knowledge of Fourier transformation and frequency optimization methods/network&lt;/li&gt;
&lt;li&gt;Independent work spirit of finding, research reading and solving a research problem&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-apply&#34;&gt;How to apply:&lt;/h2&gt;
&lt;p&gt;Just send an email to &lt;a href=&#34;mailto:jiazhen.pan@tum.de&#34;&gt;jiazhen.pan@tum.de&lt;/a&gt;, with a short CV and your grade report. We promise to get back to you within days.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Motion-Compensated MRI Reconstruction</title>
      <link>https://aim-lab.io/theses/kerstinhammernik/motionmri/</link>
      <pubDate>Fri, 07 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/kerstinhammernik/motionmri/</guid>
      <description>&lt;p&gt;Long acquisition times in Magnetic Resonance Imaging (MRI) bear the risk of patient motion, which substantially degrades the image quality. Further sources of image degradation are physiological motion, such as periodic respiratory and cardiac motion. Accelerated acquisitions can compensate for the motion. The motion information can also be derived from the acquired MRI data retrospectively and used as a correction step in image reconstruction. The objective of this thesis is to include the motion model directly in MRI reconstruction using both knowledge of the acquisition physics and machine learning. Motion-Compensated MRI reconstruction offers a wide range of opportunities for projects, where we can set the emphasis based on your interests. Please get in touch with us to find an individual topic!&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Computer Science, Biomedical Engineering or similar background&lt;/li&gt;
&lt;li&gt;Strong background in machine learning&lt;/li&gt;
&lt;li&gt;Interest in medical imaging&lt;/li&gt;
&lt;li&gt;Proficient  in Python&lt;/li&gt;
&lt;li&gt;Experience with ML frameworks, e.g., PyTorch / Tensorflow / Keras (optional)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;we-offer&#34;&gt;We offer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;a close, personal supervision&lt;/li&gt;
&lt;li&gt;to work in an interdisciplinary team&lt;/li&gt;
&lt;li&gt;to collaborate with international experts in machine learning and MR image reconstruction.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Combining longitudinal volumetric imaging and tabular data for depression prediction</title>
      <link>https://aim-lab.io/theses/vasilikisideri-lampretsa/depression_prediction/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/vasilikisideri-lampretsa/depression_prediction/</guid>
      <description>&lt;p&gt;The objective of this project is to combine volumetric imaging and non-imaging longitudinal data to accurately analyze individual patients and provide automated decisions regarding diagnosis and disease prognosis. Physicians consider various medical biomarkers and meta-data to reach a clinical decision. Thus, creating computer-assisted diagnostic systems that operate in a similar manner could be highly beneficial.&lt;/p&gt;
&lt;p&gt;The aim is to align imaging and other medical information, such as medical history, blood values, sleep habits, genetic information, and more, in the feature space using a contrastive loss. The approach will integrate multiple modalities of each patient from various time points in the same model in an end-to-end fashion. The method can be fully supervised or be used in a self-supervision scheme, in which our model can learn the aligned embedding space of imaging and non-imaging data using a proxy task from the data itself. Afterward, the learned embeddings can be finetuned for downstream tasks, such as depression prediction [1].&lt;/p&gt;
&lt;p&gt;The project will be completed under the supervision of Dr. Magdalini Paschali (Stanford University) and Vasiliki Sideri-Lampretsa (TUM). Computational resources and datasets [1] will be provided.
&lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Aadvanced knowledge in machine learning and computer vision – ability to understand and reproduce state-of-the-art publications&lt;/li&gt;
&lt;li&gt;Good programming skills in Python (numpy, pandas, seaborn, scikit-learn) and PyTorch&lt;/li&gt;
&lt;li&gt;Excellent communication skills and ability to work remotely&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting, international research project with real world medical data&lt;/li&gt;
&lt;li&gt;Freedom to come up with and propose your own ideas&lt;/li&gt;
&lt;li&gt;GPU resources&lt;/li&gt;
&lt;li&gt;An interdisciplinary team of high qualified experts in deep learning, statistics, medical imaging, and neuroscience&lt;/li&gt;
&lt;li&gt;Opportunity to participate in lab meetings as well as a workspace in TranslaTUM&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Paschali, M., Kiss, O., Zhao, Q., Adeli, E., Podhajsky, S., Müller-Oehring, E.M., Gotlib, I.H., Pohl, K.M. and Baker, F.C., 2022. Detecting negative valence symptoms in adolescents based on longitudinal self-reports and behavioral assessments. Journal of Affective Disorders.&lt;/p&gt;
&lt;p&gt;[2] Brown, S.A., Brumback, T.Y., Tomlinson, K., Cummins, K., Thompson, W.K., Nagel, B.J., De Bellis, M.D., Hooper, S.R., Clark, D.B., Chung, T. and Hasler, B.P., 2015. The National Consortium on Alcohol and NeuroDevelopment in Adolescence (NCANDA): a multisite study of adolescent development and substance use. Journal of studies on alcohol and drugs, 76(6), pp.895-908.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Federated, privacy preserving deep learning for fetal MRI brain segmentation</title>
      <link>https://aim-lab.io/theses/maikdannecker/maik/</link>
      <pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/maikdannecker/maik/</guid>
      <description>&lt;p&gt;In medical domain data protection and privacy preservation is highly relevant. Therefore, clinical data of patients is usually securely stored on clinic servers without access from outside.
Publication of clinical data is difficult and cumbersome as strict privacy and data protection laws must be obeyed.
These involve anonymization of patient data, drafting of data sharing agreements, and the approval of the corresponding ethics commission.
This complex publication process is one of the key reasons for data shortage in medical domain and is often preventing machine learning approaches to reach their full potential.
Federated learning [1] paired with differential privacy [2,3] can circumvent the problem of data publication.
Rather than gathering the data from clinical sites to centrally train a machine learning model, the model is distributed to the different sites, locally trained on the (partial) data, and finally, globally aggregated [2].
Thus, patient data is never seen by third parties.&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;We want to construct a proof of concept for a federated learning approach in the domain of fetal MRI segmentation. An existing baseline segmentation model must be modified and embedded in a federated learning environment. The model must then be trained on fetal MRI scans located on several international clinic servers. Furthermore, sufficient privacy standards (e.g. differential privacy [2]) must be discussed and ensured.&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;advanced knowledge in machine learning and computer vision (experience in federated learning or differential privacy is helpful but not mandatory)&lt;/li&gt;
&lt;li&gt;good programming skills in Python and a deep learning framework (previous work is based on
PyTorch).&lt;/li&gt;
&lt;li&gt;good communication skills. The project will require you to cooperate with different clinics of various countries.&lt;/li&gt;
&lt;/ol&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;insight to an international research project with real world medical data&lt;/li&gt;
&lt;li&gt;freedom to come up with-, and to pursue your own ideas&lt;/li&gt;
&lt;li&gt;hardware (sufficient GPU resources)&lt;/li&gt;
&lt;li&gt;an interdisciplinary team of high qualified experts in image processing, deep
learning, federated learning, and differential privacy&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Jakub Konečný et al. “Federated learning: Strategies for improving communication efficiency”.
In: arXiv preprint arXiv:1610.05492 (2016).&lt;br/&gt;
[2] Georgios Kaissis et al. “End-to-end privacy preserving deep learning on multi-institutional medical
imaging”. In: Nature Machine Intelligence 3.6 (2021), pp. 473–484.&lt;br/&gt;
[3] Alexander Ziller et al. “Differentially private federated deep learning for multi-site medical image
segmentation”. In: arXiv preprint arXiv:2107.02586 (2021).&lt;br/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Non-invasive and accurate prediction of prostate cancer aggressiveness</title>
      <link>https://aim-lab.io/theses/florianhoelzl/prostate_cancer/</link>
      <pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/florianhoelzl/prostate_cancer/</guid>
      <description>&lt;p&gt;With estimates of 1 600 000 cases and more than 350 000 deaths annually worldwide, prostate cancer is among the most common cancers in men [1]. Diagnosis of prostate cancer is typically done by using ultrasound-guided needle biopsies. An approach that not only involves risks, due to the invasive nature of the method, but also generally underestimates the aggressiveness of the tumor [2]. Standard positron emission tomography (PET) imaging with prostate cancer specific tracers and specifically PSMA-PET have shown to be advantageous for delineating suspicious lesions during biopsy [3, 4].&lt;/p&gt;
&lt;p&gt;We want to use the information provided by these PET and multi-parametric MRI images to directly predict Gleason scores that accurately report the aggressiveness of the prostate cancers without the risks associated with an invasive biopsy. Recent research at our institution has produced promising results predicting Gleason scores from handcrafted radiomic features [5]. This work aims at building on top of this research and to develop an end-to-end deep learning pipeline for predicting tumor aggressiveness directly from different imaging modalities. We have exclusive access to a dataset which includes PSMA-11 PET/MRI scans, segmentation maps and the pathological information of the tumors. Additional public data is available through the &lt;a href=&#34;https://pi-cai.grand-challenge.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PI-CAI Challenge&lt;/a&gt;. The focus of this work is to build a complete pipeline for analysing multi-modal medical imaging datasets. This includes research on understanding the diverse data available, exploring different approaches for dealing with the limited dataset size (data augmentation, pre-training etc.) and finding a suitable model and evaluation metric for this use case.
&lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;p&gt;We are looking for a highly motivated Master’s student in Computer Science, Physics, Engineering or Mathematics. You will establish a comprehensive medical imaging pipeline in PyTorch to extract information from these images. You will be working together with me and under the supervision of Prof. Daniel Rückert. Importantly, we aim to publish the results of this work, with you, in a follow up study at a high-impact medical imaging conference or in an academic journal.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Strong motivation and interest in machine learning and medical imaging.&lt;/li&gt;
&lt;li&gt;Advanced programming skills in Python and a common DL framework (PyTorch, Tensorflow).&lt;/li&gt;
&lt;li&gt;Strong interest in teamwork and interdisciplinary research.&lt;/li&gt;
&lt;/ol&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of highly qualified experts in image processing, computer vision and deep learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] 1. Global Burden of Disease Cancer Collaboration (2017). Global, Regional, and National Cancer Incidence, Mortality, Years of Life Lost, Years Lived With Disability, and Disability-Adjusted Life-years for 32 Cancer Groups, 1990 to 2015: A Systematic Analysis for the Global Burden of Disease Study. JAMA Oncol. 2017;3(4):524. &lt;/br&gt;
[2] Cohen et al. (2008). Comparing the Gleason prostate biopsy and Gleason prostatectomy grading system: the Lahey Clinic Medical Center experience and an international meta-analysis. EurUrol. 2008;54(2):371-81. &lt;/br&gt;
[3] Fendler et al. (2017). Joint EANM and SNMMI procedure guideline for prostate cancer imaging: version 1.0. Eur J Nucl Med Mol Imaging. 2017;44(6):1014–24. &lt;/br&gt;
[4] Maurer et al. (2016). Current use of PSMA-PET in prostate cancer management. Nat Rev Urol. 2016;13(4):226–35. &lt;/br&gt;
[5] Solari et al. (2021). The added value of PSMA PET/MR radiomics for prostate cancer staging. Eur J Nucl Med Mol Imaging. 2022;49:527–538.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Adversarial attacks in collaborative machine learning</title>
      <link>https://aim-lab.io/theses/dmitriiusynin/attacks/</link>
      <pubDate>Wed, 27 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/dmitriiusynin/attacks/</guid>
      <description>&lt;p&gt;Collaborative machine learning has became the new paradigm-of-choice when it comes to training deep learning models in many fields, including medical image analysis. Due to a number of data protection and governance regulations being introduced, direct data sharing for such training is rendered problematic. As a result implementations that rely on local training, such as federated learning (FL) have been widely adopted. However, a number of studies [1,2] have shown that such paradigms are deeply vulnerable to adversarial influence either in the form of privacy violation [3] or utility degradation [4]. Fortunately for the research community, such attacks are often very fragile and require a number of assumptions to hold in practise. The aim of this project is to explore the recent advances in adversarial machine learning in order to investigate how to adapt them to the real-world machine learning contexts in order to encourage the research community and policymakers to employ safe, robust and privacy-preserving systems when working with sensitive personally-identifying information.&lt;/p&gt;
&lt;p&gt;This project is deliberately very open-ended, as there is a large number of various attack vectors that could be pursued: attacks on membership, reconstruction of sensitive attributes or training samples, insertion of auxiliary learning tasks etc. Our lab has experience primarily with privacy-oriented attacks on machine learning, but we are otherwise happy to consider students with interest in any other attack formulation.&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Basic familiarity with existing collaborative machine learning paradigms, preferably federated learning.&lt;/li&gt;
&lt;li&gt;Basic familiarity with attacks on machine learning models (all information can be found in the references).&lt;/li&gt;
&lt;li&gt;Advanced knowledge of machine learning and computer vision.&lt;/li&gt;
&lt;li&gt;Excellent programming skills in Python and PyTorch.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ability to perform cutting edge research in the field of adversarial and privacy-preserving machine learning.&lt;/li&gt;
&lt;li&gt;Closely working and collaborating with a team of experts in privacy-preserving machine learning, deep learning and medical image analysis.&lt;/li&gt;
&lt;li&gt;This project is targeting publication at leading privacy and security conferences/journals (e.g. PETS)
&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Usynin, Dmitrii, et al. &amp;ldquo;Adversarial interference and its mitigations in privacy-preserving collaborative machine learning.&amp;rdquo; Nature Machine Intelligence 3.9 (2021): 749-758.&lt;/p&gt;
&lt;p&gt;[2] Usynin, Dmitrii, et al. &amp;ldquo;Distributed Machine Learning and the Semblance of Trust.&amp;rdquo; arXiv preprint arXiv:2112.11040 (2021).&lt;/p&gt;
&lt;p&gt;[3] Shokri, Reza, et al. &amp;ldquo;Membership inference attacks against machine learning models.&amp;rdquo; 2017 IEEE Symposium on Security and Privacy (SP). IEEE, 2017.&lt;/p&gt;
&lt;p&gt;[4] Bagdasaryan, Eugene, et al. &amp;ldquo;How to backdoor federated learning.&amp;rdquo; International Conference on Artificial Intelligence and Statistics. PMLR, 2020.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Defending collaborative machine learning through interpretability methods</title>
      <link>https://aim-lab.io/theses/dmitriiusynin/attacks_path/</link>
      <pubDate>Wed, 27 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/dmitriiusynin/attacks_path/</guid>
      <description>&lt;p&gt;Collaborative machine learning has became the new paradigm-of-choice when it comes to training deep learning models in many fields, including medical image analysis. Due to a number of data protection and governance regulations being introduced, direct data sharing for such training is rendered problematic. As a result implementations that rely on local training, such as federated learning (FL) have been widely adopted. However, a number of studies [1,2] have shown that such paradigms are deeply vulnerable to adversarial influence either in the form of privacy violation [3] or utility degradation [4].&lt;/p&gt;
&lt;p&gt;This project aims to unite the areas of interpretable deep learning and defenses against attacks on collaborative learning. A number of approaches identifying the so-called critical neurons and pathways have previously been proposed to aid the community in interpretation of the predictions made by deep learning models[5,6,7]. We want to determine if these neurons/pathways are also critical for the adversary when it comes to extraction of information or destruction of utility of a jointly trained model.&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Basic familiarity with existing collaborative machine learning paradigms, preferably federated learning.&lt;/li&gt;
&lt;li&gt;Basic familiarity with attacks on machine learning models (all information can be found in the references).&lt;/li&gt;
&lt;li&gt;Advanced knowledge of machine learning and computer vision.&lt;/li&gt;
&lt;li&gt;Excellent programming skills in Python and PyTorch.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ability to perform cutting edge research in the field of adversarial and privacy-preserving machine learning.&lt;/li&gt;
&lt;li&gt;Closely working and collaborating with a team of experts in privacy-preserving machine learning, deep learning and medical image analysis.&lt;/li&gt;
&lt;li&gt;This project is targeting publication at leading privacy and security conferences/journals (e.g. PETS)
&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Usynin, Dmitrii, et al. &amp;ldquo;Adversarial interference and its mitigations in privacy-preserving collaborative machine learning.&amp;rdquo; Nature Machine Intelligence 3.9 (2021): 749-758.&lt;/p&gt;
&lt;p&gt;[2] Usynin, Dmitrii, et al. &amp;ldquo;Distributed Machine Learning and the Semblance of Trust.&amp;rdquo; arXiv preprint arXiv:2112.11040 (2021).&lt;/p&gt;
&lt;p&gt;[3] Shokri, Reza, et al. &amp;ldquo;Membership inference attacks against machine learning models.&amp;rdquo; 2017 IEEE Symposium on Security and Privacy (SP). IEEE, 2017.&lt;/p&gt;
&lt;p&gt;[4] Bagdasaryan, Eugene, et al. &amp;ldquo;How to backdoor federated learning.&amp;rdquo; International Conference on Artificial Intelligence and Statistics. PMLR, 2020.&lt;/p&gt;
&lt;p&gt;[5] Khakzar, Ashkan, et al. &amp;ldquo;Neural response interpretation through the lens of critical pathways.&amp;rdquo; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.&lt;/p&gt;
&lt;p&gt;[6] Zhang, Yang, et al. &amp;ldquo;Fine-grained neural network explanation by identifying input features with predictive information.&amp;rdquo; Advances in Neural Information Processing Systems 34 (2021): 20040-20051.&lt;/p&gt;
&lt;p&gt;[7] Bau, David, et al. &amp;ldquo;Network dissection: Quantifying interpretability of deep visual representations.&amp;rdquo; Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: AI against SARS-CoV-2</title>
      <link>https://aim-lab.io/theses/danielrueckert/ai-virus/</link>
      <pubDate>Sat, 02 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/danielrueckert/ai-virus/</guid>
      <description>&lt;p&gt;Viruses interact with cellular proteins to replicate and spread. We aim to gain functional insights into the mode of action of cellular proteins, enabling us to better understand how different viruses like SARS-CoV-2 cause disease.&lt;/p&gt;
&lt;p&gt;We are using genetic ablation of cellular proteins and viruses that express a green fluorescent protein (GFP), allowing us to continuously follow the infection by live-cell fluorescent microscopy in a time-resolved manner.  The resulting, very rich dataset (consisting of ~60.000 images per virus tested), will be used to search for patterns allowing to classify the function of the perturbed gene in relation to the infecting virus.  For instance, the GFP intensity/area, the localization, and spatial proximity of a GFP signal over time contains information on virus replication and spread.  This work aims to establish and apply unbiased machine learning algorithms to understand these functional links between the cell and the viruses and to identify the proteins and perturbations that contribute to virus growth and virus restriction. This algorithm will further be used to study the influence of inflammatory events and treatment with drug libraries.
&lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;p&gt;We are looking for a highly motivated Master’s student who will establish a comprehensive bioinformatics pipeline to extract information from these images. You will be working together with computational scientists at the AI in Medicine Lab and wet-lab scientists (Prof. Andreas Pichlmair group, Virology). Importantly, your results will be functionally tested iteratively and used to further improve the predictive power of your model.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Advanced programming skills in Python&lt;/li&gt;
&lt;li&gt;Strong background in deep learning and image analysis&lt;/li&gt;
&lt;li&gt;Strong interest in working in an interdisciplinary team&lt;/li&gt;
&lt;/ol&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biology and medicine.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
</description>
    </item>
    
    <item>
      <title>Master-Seminar: Unsupervised Anomaly Detection in Medical Imaging</title>
      <link>https://aim-lab.io/theses/felixmeissen/seminar/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/felixmeissen/seminar/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./cover.jpg&#34; alt=&#34;cover image&#34;&gt;&lt;/p&gt;
&lt;p&gt;Anomaly detection aims to identify patterns that do not conform to the expected normal distribution.
Despite its importance for clinical applications, the detection of outliers is still a very challenging task due to the
rarity, unknownness, diversity and heterogeneity of abnormalities.
Basic problem formulations to recent advances in the field will be discussed.
This includes, but is not limited to: reconstruction-based
auto-encoders (AE) adversarial methods, diffusion models, and others.
In short this course offers students to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learn how to critically read and understand scientific papers&lt;/li&gt;
&lt;li&gt;Get hands-on practice in implementing anomaly detection methods on medical data&lt;/li&gt;
&lt;li&gt;Practice the presentation and discussion of experimental results&lt;/li&gt;
&lt;li&gt;Get a multi-facetted view in multiple guest lecturers by reknown researchers in the field of anomaly detection&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Understanding of Deep Learning and Neural Networks, demonstrated through the completion of at least one learning or deep learning course (e.g. Intro to Deep Learning, Advanced Deep Learning, Machine Learning, or equivalent).&lt;/li&gt;
&lt;li&gt;Good coding skills in Python&lt;/li&gt;
&lt;li&gt;Coding experience in PyTorch&lt;/li&gt;
&lt;li&gt;Interest in medical imaging&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Students will select a relevant paper and present it critically&lt;/li&gt;
&lt;li&gt;They will then implement the method in the paper given our framework and data&lt;/li&gt;
&lt;li&gt;Experimental results will be presented to the lecturers and fellow students in a poster session&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- ## Preliminary meeting
A preliminary meeting will take place on 31st of January, 2023 at 11:30 on zoom with the following details: https://tum-conf.zoom.us/j/69075883519 

Meeting ID: 690 7588 3519 \
Passcode: 850155  --&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Unsupervised deep learning for vessel segmentation in optical coherence tomography angiographs</title>
      <link>https://aim-lab.io/theses/old/octa/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/old/octa/</guid>
      <description>&lt;p&gt;Optical coherence tomography angiography (OCTA) is an imaging technique that visualizes blood vessels by detecting motion of red blood cells in sequential scans [1]. It has seen initial adoption for the diagnosis and monitoring of clinical conditions that affect the retinal vasculature, such as several different eye diseases or multiple sclerosis [2, 3]. However, its effective clinical use is often impeded by the occurrence of imaging artifacts and lack of tools that can extract the vessel maps from the images. Only few studies have explored the use of deep-learning-based segmentation to delineate vessels in two-dimensional OCTA images [4, 5]. The development of three-dimensional (3D) segmentation algorithms has proven difficult due to a lack of publicly available datasets with ground truth annotations, which are difficult and time-consuming to acquire for the large and complex OCTA images [5].&lt;/p&gt;
&lt;p&gt;This project aims at tackling the problem of 3D vessel segmentation in OCTA images using unsupervised and weakly supervised deep learning. The prospective student will adopt existing deep-learning-based segmentation algorithms so that these can be trained using self-supervision and noisy annotations. All developed methods will be evaluated on a large dataset of OCTA images collected at the Klinikum rechts der Isar.&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;your-qualifications&#34;&gt;Your qualifications:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Enthusiasm for deep learning and biomedical imaging.&lt;/li&gt;
&lt;li&gt;Advanced knowledge of machine learning and computer vision. Ideally, prior work experience using deep learning for image processing.&lt;/li&gt;
&lt;li&gt;Excellent programming skills in Python, PyTorch or Tensorflow. Familiarity with C++ is helpful.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;An exciting research project with many possibilities to bring in your own ideas.&lt;/li&gt;
&lt;li&gt;Close supervision and access to state-of-the-art computer hardware.&lt;/li&gt;
&lt;li&gt;The chance to work in a team of experts in image processing, deep learning, biomedical engineering and medicine.&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] De Carlo, T. E., Romano, A., Waheed, N. K., &amp;amp; Duker, J. S. (2015). A review of optical coherence tomography angiography (OCTA). International journal of retina and vitreous, 1(1), 5. &lt;/br&gt;
[2] Chalam, K. V., &amp;amp; Sambhav, K. (2016). Optical coherence tomography angiography in retinal diseases. Journal of ophthalmic &amp;amp; vision research, 11(1), 84. &lt;/br&gt;
[3] Feucht, N., Maier, M., Lepennetier, G., Pettenkofer, M., Wetzlmair, C., Daltrozzo, T., &amp;hellip; &amp;amp; Knier, B. (2019). Optical coherence tomography angiography indicates associations of the retinal vascular network and disease activity in multiple sclerosis. Multiple Sclerosis Journal, 25(2), 224-234. &lt;/br&gt;
[4] Mou, L., Zhao, Y., Chen, L., Cheng, J., Gu, Z., Hao, H., &amp;hellip; &amp;amp; Liu, J. (2019, October). CS-Net: channel and spatial attention network for curvilinear structure segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 721-730). Springer, Cham. &lt;/br&gt;
[5] Ma, Y., Hao, H., Xie, J., Fu, H., Zhang, J., Yang, J., &amp;hellip; &amp;amp; Zhao, Y. (2020). ROSE: a retinal OCT-angiography vessel segmentation dataset and new model. IEEE transactions on medical imaging, 40(3), 928-939. &lt;/br&gt;
[6] Schneider, M., Reichold, J., Weber, B., Székely, G., &amp;amp; Hirsch, S. (2012). Tissue metabolism driven arterial tree generation. Medical image analysis, 16(7), 1397-1414. &lt;/br&gt;
[7] Kato, H., Beker, D., Morariu, M., Ando, T., Matsuoka, T., Kehl, W., &amp;amp; Gaidon, A. (2020). Differentiable rendering: A survey. arXiv preprint arXiv:2006.12057.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Machine Learning for Analysis of Sarcoma</title>
      <link>https://aim-lab.io/theses/old/sarcoma/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/old/sarcoma/</guid>
      <description>&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Early diagnosis of musculoskeletal tumours is crucial for successful therapy and treatment. The sooner a potential malignant growth is detected, the more effective the next steps in therapy and the better a prognosis usually becomes. The rarity of musculoskeletal tumours, potentially inexperienced clinicians with this certain entity, as well as unspecific anamnesis and clinical manifestations may delay the final diagnosis. Whereas currently available imaging modalities yield considerable insights into tumour staging and grading, biopsy remains the gold standard for final diagnosis. Yet, the planning of a successful biopsy yielding sufficient material might require time aside from a high level of experience and may delay the final diagnosis even further.&lt;/p&gt;
&lt;p&gt;The complexity in conjunction with multimodal approaches in fully grasping this disease provide a very suitable foundation for modern artificial intelligence algorithms. Not only for diagnostic purposes, but also for treatment planning or prognosis prediction, machine learning and deep learning algorithms are popular techniques in many disciplines at this time.&lt;/p&gt;
&lt;h2 id=&#34;tasks&#34;&gt;Tasks&lt;/h2&gt;
&lt;p&gt;Various topics in the domain of musculoskeletal tumor analysis are available for a master thesis in computer science and can be discussed during an interview.&lt;/p&gt;
&lt;p&gt;The main tasks will involve:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analysis of sarcoma with machine/deep learning&lt;/li&gt;
&lt;li&gt;Coping with very limited and unbalanced datasets&lt;/li&gt;
&lt;li&gt;Adaption to medicine specific issues with AI&lt;/li&gt;
&lt;li&gt;Presenting and discussing results&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-offer&#34;&gt;What we offer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Access to very rare medical data&lt;/li&gt;
&lt;li&gt;Highly educated &amp;amp; interdisciplinary environment&lt;/li&gt;
&lt;li&gt;Top level hardware for scientific computing&lt;/li&gt;
&lt;li&gt;Constant feedback from medical and computer science experts&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Advanced knowledge of deep learning with imaging data&lt;/li&gt;
&lt;li&gt;Beneficial but not necessary: experience in medicine / oncology&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Rechl H, Kirchhoff C, Wörtler K, Lenze U, Töpfer A, von Eisenhart-Rothe R. Diagnostik von malignen Knochen- und Weichteiltumoren [Diagnosis of malignant bone and soft tissue tumors]. Orthopade. 2011 Oct;40(10):931-41; quiz 942-3. German. doi: 10.1007/s00132-011-1821-7. PMID: 21874363&lt;/p&gt;
&lt;p&gt;[2] He, Y. et al. Deep learning-based classification of primary bone tumors on radiographs: A preliminary study. EBioMedicine 62, 103121 (2020)&lt;/p&gt;
&lt;p&gt;[3] Hussain Z, Gimenez F, Yi D, Rubin D. Differential Data Augmentation Techniques for Medical Imaging Classification Tasks. AMIA Annu Symp Proc. 2018;2017:979-984. Published 2018 Apr 16.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Distributionally robust neural networks in medical imaging</title>
      <link>https://aim-lab.io/theses/old/robust/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/old/robust/</guid>
      <description>&lt;p&gt;Deep learning has revolutionized the field of medical imaging. However, the performance of a model drops when the distribution of the test data is different from the distribution of the training data. This is especially critical in a medical setting, where the amount of labelled training data is often limited, and in particular for the application in clinical routine, where the distribution of the test data cannot be controlled. Typical problems are here domain shift, bias in the training data and out-of-distribution samples (e.g., pathologies, image artefacts).
In this project, we will explore distributionally robust optimization (DRO) [1,2] for deep learning in medical imaging. Instead of minimizing the average loss of a training set, DRO minimizes the worst-case risk and with this optimizes the performances on ”hard” examples. The student will adapt and develop novel methods using DRO for medical imaging applications (classification, segmentation and/or registration.&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Prior experience and good understanding in machine learning and statistics.&lt;/li&gt;
&lt;li&gt;Very good programming skills in python (and pytorch).&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;J. Duchi and H. Namkoong: Learning models with uniform performance via distributionally robust optimization. arXiv preprint arXiv:1810.08750 (2018)&lt;/li&gt;
&lt;li&gt;S. Sagawa et al.: Distributionally Robust Neural Networks, In Proc. ICLR (2020)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Out-of-distribution detection using contrastive training for medical imaging</title>
      <link>https://aim-lab.io/theses/old/oodd/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/old/oodd/</guid>
      <description>&lt;p&gt;Deep learning has revolutionized the field of medical imaging. However, the performance of a model drops when the distribution of the test data is different from the distribution of the training data. This is especially critical in a medical setting, where the amount of labelled training data is often limited, and in particular for the application in clinical routine, where the distribution of the test data cannot be controlled. The automatic detection of such Out-of-Distribution (OoD) samples at inference is important for the design of reliable models, but also to identify poor quality images and pathologies not seen during training.&lt;/p&gt;
&lt;p&gt;Recently, contrastive learning has shown to provide state-of-the-art results for OoD in image classification benchmarks [1]. Contrastive learning is an approach to formulate the task of finding similar and dissimilar samples during training. One advantage of the proposed method is that no OoD data is required during training.
The aim of this project is to explore OoD detection in deep learning in general, and in particular the use of contrastive training. The student will develop and implement (novel) methods for image classification, segmentation, and/or registration in a medical application.&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Prior experience and good understanding in machine learning and statistics.&lt;/li&gt;
&lt;li&gt;Very good programming skills in python (and pytorch).&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;J. Winkens et al.: Contrastive Training for Improved Out-of-Distribution Detection. arXiv preprint arXiv:2007.05566 (2020)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>MSc Thesis: Privacy-preserving Deep Learning in Medical Imaging</title>
      <link>https://aim-lab.io/theses/georgioskaissis/ppml/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://aim-lab.io/theses/georgioskaissis/ppml/</guid>
      <description>&lt;p&gt;Privacy-preserving artificial intelligence techniques such as differential privacy, encryption and multi-party computation can reconcile the needs for data utilisation and data protection in the medical domain, as mandated by legal and ethical requirements. Their widespread utilisation requires innovations in the fields of distributed machine learning (federated learning) as well as answering open questions in privacy research and cryptography.&lt;/p&gt;
&lt;p&gt;We are seeking an MSc candidate with a strong background in machine learning, preferrably with previous exposure to medical imaging topics to complete their thesis at our institute. Experience with distributed systems, privacy and security issues or cryptology is desirable.
We are offering an engaging work environment, a large, diverse team, close personal supervision and collaboration with AI, medical and privacy-preserving ML experts.&lt;/p&gt;
&lt;p&gt;We can accommodate a wide range of interests from your side! Please get in touch with us to find an appropriate topic. We are also able to supervise guided research projects, smaller in scope than full MSc theses.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
